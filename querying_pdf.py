# -*- coding: utf-8 -*-
"""Querying pdf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gae6sAVkuUqI4FzC078r6dX7apr4nN7m
"""

!pip install langchain
!pip install PyPDF2
!pip install faiss-cpu
!pip install tiktoken

!pip install google-generativeai

!pip install langchain-google-genai

!pip install langchain-community

from PyPDF2 import PdfReader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model = "gemini-1.5-flash",
    temperature = 0,
    max_tokens = None,
    timeout= None,
    max_retries= 2,
    google_api_key="AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI"
)

# provide the path of  pdf file/files.
pdfreader = PdfReader('/content/Machine Learning.pdf')

from typing_extensions import Concatenate
# read text from pdf
raw_text = ''
for i, page in enumerate(pdfreader.pages):
    content = page.extract_text()
    if content:
        raw_text += content

raw_text

# We need to split the text using Character Text Split such that it sshould not increse token size
text_splitter = CharacterTextSplitter(
    separator = "\n",
    chunk_size = 800,
    chunk_overlap  = 200,
    length_function = len,
)
texts = text_splitter.split_text(raw_text)

len(texts)

embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key="AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI"
)

document_search = FAISS.from_texts(texts, embeddings)

document_search

from langchain.chains.question_answering import load_qa_chain

!pip install --upgrade langchain

from langchain.llms import GooglePalm

chain = load_qa_chain(ChatGoogleGenerativeAI(
    model = "gemini-1.5-flash",
    temperature = 0,
    max_tokens = None,
    timeout= None,
    max_retries= 2,
    google_api_key="AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI"
)
, chain_type="stuff")

query = "What is machine learning?"
docs = document_search.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "What is Association Learning?"
docs = document_search.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "vikisit bharat"
docs = document_search.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "Types of regression"
docs = document_search.similarity_search(query)
chain.run(input_documents=docs, question=query)

