{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Gae6sAVkuUqI4FzC078r6dX7apr4nN7m",
      "authorship_tag": "ABX9TyNdcfOgLICxOeCj2e5FGeZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanajapriya26/Machine-Learning/blob/main/Querying_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adLx3RmsVBp4",
        "outputId": "01faec38-6fcf-4231-88f6-c41410ae8011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.8-py3-none-any.whl (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.6/987.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.19 (from langchain)\n",
            "  Downloading langchain_core-0.2.19-py3-none-any.whl (366 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.5/366.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.86-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.19->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.8 langchain-core-0.2.19 langchain-text-splitters-0.2.2 langsmith-0.1.86 orjson-3.10.6\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLw5veCSVKlv",
        "outputId": "0b79792e-561a-40ea-9144-e652ce5f9ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ucKD5qAaVQwb",
        "outputId": "bb932fa2-4454-421c-8bee-7dd5a1fe376c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl (36 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.2.19)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (0.1.86)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2024.7.4)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "Successfully installed google-ai-generativelanguage-0.6.6 google-generativeai-0.7.2 langchain-google-genai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d418519dc56c47789f26bc869e6ce831"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6WR2x4vWDsF",
        "outputId": "44d4658e-0bf2-4dec-c148-94252fd6f5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.8)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "D1pGjXNdVZ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "ggUxki4PXqBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    temperature = 0,\n",
        "    max_tokens = None,\n",
        "    timeout= None,\n",
        "    max_retries= 2,\n",
        "    google_api_key=\"AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "59X-1Lw1V5mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('/content/Machine Learning.pdf')"
      ],
      "metadata": {
        "id": "o_lJhH6lXlEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "3yj0_S2XXuFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Ao8ybzfvYey6",
        "outputId": "e9779d27-4704-4e04-cd9b-a2506994f4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Machine learning  \\n  \\nUNIT -I: INTRODUCTION TO MACHINE LEARNING: What is machine \\nlearning, Problems Machine Learning Can Solve, Framework for developing \\nMachine Learning Models, Examples of Machine Learning Applications - \\nLearning Associations, Classification, Regression, Unsupervised Learning, and \\nReinforcement Learning   \\nUNIT -II DIMENSIONALITY REDUCTION:  Introduction, Feature Selection -\\nForward selection, Bidirectional Elimination, Principal Component analysis, L1 \\nand L2 regularization, Linear Di scriminant Analysis, Basics of t -SNE, Information \\nvalue and Weight of evidence   \\nUNIT -III: CLASSIFICATION: What is Classification, General Approach to \\nClassification, Multi -class classification, multi -label classification, Binary \\nClassification, Logistic Re gression, Decision Trees, k -Nearest Neighbour \\nAlgorithm, Naive Bayesian Classifier and SVM classifier MODEL METRICS: ROC \\nCurves, Confusion matrix, Holdout Method, Cross Validation, Bootstrap  \\nUNIT -IV CLUSTERING:  Basic Clustering Methods: Partitional Cluste ring, \\nHierarchical Clustering, K -Means Clustering. Expectation -Maximization (EM) \\nAlgorithm and Gaussian Mixtures Clustering INTRODUCTION TO NEURAL \\nNETWORKS: Neural Network Representations, Appropriate Problems for Neural \\nNetwork Learning, Perceptrons, Multi layer Networks and the Back propagation \\nAlgorithm, Remarks on Back Propagation Algorithm,   \\nUNIT -V Ensemble Methods:  Introduction -What is Ensembling methods, \\nWhy Ensembling methods, Applications of Ensemble methods, Boosting, \\nBagging, Combinational Methods -Benefits of combination, Averaging, Voting  \\n \\n \\n \\n \\n  \\nIntroduction to Machine Learning:  \\nWhat is machine learning?  \\n“A computer program is said to learn from Experi ence E with respect \\nto some class of task T and performance measure P if its \\nperformance at tasks improves with the experiences ”. \\nMachine learning is a field of study in artificial intelligence concerned with the development and \\nstudy of statistical algorithms that can learn from data and generalize to unseen data, and thus \\nperform tasks without explic it instructions  \\nProblems Machine Learning can solve:  \\nMachine learning can solve many real -world problems. Some \\nexamples include:  \\nIdentifying spam  \\nMaking product recommendations  \\nCustomer segmentation  \\nImage and video recognition  \\nFraudulent transactions  \\nDema nd forecasting  \\nVirtual personal assistants  \\nSentiment analysis  \\nMedical  diagnosis  \\nFramework for Developing machine learning Models:  \\nMachine Learning frameworks are used in the domains related to computer \\nvision, natural language processing, and time -series predictions. They are \\nalso used with structured data typically represented in a tabular form to \\nperform linear regression and logistic regression to predict or classify the \\ndata.  1. TensorFlow  \\nIt has a collection of pre -trained models and is one of the mos t popular \\nmachine learning frameworks that help engineers, deep neural scientists to \\ncreate  deep  learning  algorithms  and models. Google Brain team is the \\nbrainchild beh 2 ind this open -source framework. ML developers can apply it \\nin dataflow  programmers to deal with numerical computation & large -scale \\nsupervised and unsupervised learning. TensorFlow clusters together machine \\nlearning and deep learning models and renders them through large datasets to \\ntrain these models to think and create sensible outcomes o n their own. It can \\noperate on both CPUs and GPUs  \\n \\n2. Keras     \\nKeras  is an open -source framework developed on top of TensorFlow. It is \\nwritten in Python and can efficiently run on GPUs and CPUs. After going \\nthrough a long research and adaptation phase, Keras became the choice of \\nhigh -level  neural  network . François Chollet is a Google engineer who designed \\nit to be fast, easy to implement, and modular by nature. ML developers can \\napply it in different domains like healthcare, corporate insights, sales \\npredictions, customer support, virtual assistants, etc.  \\n \\n3. MXNet  \\nMXNet is a choice of all Deep Learning developers. It supports scalability for a \\nwide range of GPUs and programming languages. MXNet is customizable and \\nportable and can wield algorithms that r equire long & short -term memory \\nnetworks and  convolutional  neural  networks . Its application spreads from \\ntransportation to healthcare systems to manufacturing and in various other \\nfields.  \\n4. Caffe \\nCaffe, abbreviated as Convolutional Architecture for Fast Feature Embedding, \\nis another ML and DL framework written in C++. It is ideal for production edge \\ndelivery, image categorization, and experimenting with research methods. \\nMost startups, mid -sized firms, and academicians use Caffe to deal \\nwith  computer  vision and speech recognition projects. It has an interface that \\nenables developers to transit within CPU & GPU.  \\n \\n5.  H2O \\nIt is another open -source, business -oriented machine learning Framework. It \\nhelps in implementing  predictive  analytics  with mathematics to  make decisions \\nbased on granular data. It has database -agnostic support with open -source \\nBreed technology to train machines based on data insights. The core code \\nof H2O  is in Java, and the REST API enables accessing or embedding it from any \\nexternal sourc e code or script. Machine learning professionals can extend H2O \\nto work with existing programming languages and tools. ML developers apply \\nit in customer intelligence, analyzing insurance, advertising technology, risk \\nanalysis, healthcare, fraud analysis, etc. \\n \\n6. Theano  \\nTheano  was built on top of NumPy and is one of the fastest ML libraries. It got \\nreleased under the BSD license and written in Python and CUDA. Developers \\nuse it to work with multi -dimensional arrays and allow users to optimize \\nmathematical representations in ML projects. Even though Theano is \\ncomfortable with both GPU and CPU systems, it can yield faster results when \\ndevelopers make it work with the earlier one. This machine learning tool can \\nrender its tasks 140 times faster when used in GP U architectures. Theano finds \\nextensive applications in  finance  and logistic projects as a popular machine \\nlearning tool.   \\n7. Shogun  \\nIt is quite a venerable, old, and open -source machine learning library. It \\nbundles a vast collection of data structures and  ML algorithms. It is written in \\nC++ and gels perfectly with C++. Due to its humbleness towards C++, it is \\npopular in the academics and learning industry. Shogun also exhibits \\ncompatibility with several other languages like Python, C#, Java, Lua, R, Ruby, \\netc. Developers use Shogun to process large -scale data for  machine  learning  \\napplications . ML Developers can work on a broad range of projects that \\nrequire regression,  classification , or explorative analysis. ML developers apply \\nShogun in research, educatio n, and  NLP projects.  \\n \\n8.PyTorch  \\nPyTorch  was developed  by FAIR, Facebook AI Research. In early 2018, the FAIR \\nteam merged Caffe2, another ML framework, into PyTorch . It is the leading \\ncompetitor to TensorFlow. When engineers are deciding to use a ML platform, \\ntheir choice generally comes down to, “Do we use TensorFlow or PyTorch?” \\nThey each serve their purposes but are pretty interchangeable.  \\nLike TensorFlow, PyTorch : \\n\\uf0b7 Does regression, classification, neural networks, etc.  \\n\\uf0b7 Runs on both CPUs and GPUs.  \\nPyTorch is considered more pythonic. Where TensorFlow can get a model up \\nand running faster and with some customization, PyTorch  is considered more \\ncustomizable, following a more traditional object -oriented programming \\napproach through building classes  \\n9.scikit -Learn  \\nScikit -learn  is one of the oldest machine learning frameworks developed \\nby David  Cournapeau  as a Google Summer of Co de project in 2007. Available as a Python library, it supports both supervised and unsupervised \\nlearning algorithms.  Scikit -learn is built on top of  SciPy , an opensource \\nscientific toolkit for Python developers. Behind the scenes, SciPy \\nuses  NumPy  for math ematical calculations,  Matplotlib  for \\nvisualization,  Pandas  for data manipulation, and  SymPy  for its algebra \\ncapabilities. Scikit -learn extends the SciPy stack through modeling and \\nlearning capabilities.  \\n10.Eclipse Deeplearning4j  \\nDeeplearning4j is one of the few machine learning frameworks natively \\nwritten in Java targeting the Java Virtual Machine (JVM). It is developed by \\na group of ML developers based in San Francisco and supported \\ncommercially by the startup  Skymind . Deeplearni ng4j was donated to the \\nEclipse Foundation in October 2017. The library is compatible with Clojure \\nand Scala.  For clustering and distributed training, Deeplearning4j is \\nintegrated with Apache Spark and Apache Hadoop. It is also integrated with \\nNVIDIA CUDA runtime to perform GPU operations and distributed training \\nacross multiple GPUs.  \\nExamples of Machine Learning:  \\n \\n \\n1. Speech & Image Recognition  \\nComputer Speech  Recognition  or Automatic  Speech Recognition  helps to \\nconvert speech into text. Many applications convert the live speech into an \\naudio file format and later convert it into a text file. Voice search, voice dialing, \\nand appliance control  are some real -world examples of speech \\nrecognition.  Alexa and Google Home  are the most widely used speech \\nrecognition software Similar to speech recognition,  Image recognition  is also the \\nmost widely used example of Machine Learning technology that helps identify \\nany object in the form of a digital image. There are s ome real -world examples of \\nImage recognition, such as, Tagging the name on any photo as we have seen on \\nFacebook . It is also used in recognizing handwriting by segmenting a single letter \\ninto smaller images.  \\n2. Traffic alerts using Google Map  \\nGoogle Map is  one of the widely used applications whenever anyone goes out \\nto reach the correct destination. The map helps us find the best route or fastest \\nroute, traffic, and much more information. But how it provides this information \\nto us? Google map uses different  technologies, including machine learning \\nwhich  collects information from different users, analyze that information, \\nupdate the information, and make predictions.  With the help of predictions, it \\ncan also tell us the traffic before we start our journey. Ma chine Learning also \\nhelps identify the best and fastest route while we are in traffic using Google \\nMaps.  \\n3. Chatbot (Online Customer Support)  \\nA chatbot is the most widely used software in every industry like  banking, \\nMedical, education, health,  etc. You can see chatbots in any banking application \\nfor quick online support to customers. These chatbots also work on the concepts \\nof Machine Learning. The programmers feed some basic questions and answers \\nbased on the frequently asked queries. So, whenever a cus tomer asks a query, \\nthe chatbot recognizes the question\\'s keywords from a database and then \\nprovides appropriate resolution to the customer. This helps to make quick and \\nfast customer service facilities to customers.  \\n4.Google Translation  \\nSuppose you work on an international banking project like French, German, etc., \\nbut you only know English. In that case, this will be a very panic moment for you because you can\\'t proceed further without reviewing documents. Google \\nTranslator software helps to translate an y language into the desired language. \\nSo, in this way, you can convert French, German, etc., into English, Hindi, or any \\nother language. This makes the job of different sectors very easy as a user can \\nwork on any country\\'s project hassle -free.  \\n5. Predictio n \\nPrediction system also uses Machine learning algorithms for making predictions. \\nThere are various sectors where predictions are used. For example, in bank loan \\nsystems, error probability can be determined using predictions with machine \\nlearning. For this , the available data are classified into different groups with the \\nset of rules provided by analysts, and once the classification is done, the error \\nprobability is predicted.  \\n6. Extraction  \\nOne of the best examples of machine learning is  the extraction of i nformation . \\nIn this process, structured data is extracted from unstructured data, and which \\nis used in predictive analytics tools. The data is usually found in a raw or \\nunstructured form that is not useful, and to make it useful,  the \\nextraction  process is used. Some real -world examples of extraction are:  \\no Generating a model to predict vocal cord disorders.  \\no Helping diagnosis and treatment of problem faster.  \\n7. Statistical Arbitrage  \\nArbitrage is an automated trading process, which is used in the finance \\nindust ry to manage a large volume of securities. The process uses a  trading \\nalgorithm  to analyze a set of securities using economic variables and \\ncorrelations. Some examples of statistical arbitrage are as follows:  \\no Algorithmic trading that analyses a market microstructure  \\no Analyze large data sets  \\no Identify real -time arbitrage opportunities  \\no Machine learning optimizes the arbitrage strategy to enhance results.  8. Auto -Friend Tagging Suggestion  \\nOne of the popular examples of machine learning is  the Auto -friend tag ging \\nsuggestions  feature by Facebook. Whenever we upload a new picture on \\nFacebook with friends, it suggests to tag the friends and automatically provides \\nthe names. Facebook does it by using  DeepFace , which is a facial recognition \\nsystem created by Facebo ok. It identifies the faces and images also.  \\n9. Self -driving cars  \\nThe future of the automobile industry is self -driving cars. These are driverless \\ncars, which are based on concepts of deep learning and machine learning. \\nSome commonly used machine learning algorithms in self -driving cars \\nare Scale -invariant feature transform (SIFT), AdaBoost, TextonBoost, YOLO(You \\nonly look once  \\n10. Ads Recommendation  \\nNowadays, most people spend multiple hours on google or the internet surfing. \\nAnd while working on any webpa ge or website, they get multiples ads on each \\npage. But these ads are different for each user even when two users are using \\nthe same internet and on the same location. These ads recommendations are \\ndone with the help of machine learning algorithms. These a ds recommendations \\nare based on the search history of each user. For example, if one user searches \\nfor the Shirt on Amazon or any other e -commerce website, he will get start ads \\nrecommendation of shirts after some time.  \\n11. Video Surveillance  \\nVideo Surveillance is an advanced application of AI and machine learning, which \\ncan detect any crime before it happens. It is much efficient than observed by a \\nhuman because it is a much difficult and boring task for a human to keep \\nmonitoring multiple vid eos; that\\'s why machines are the better option. Video \\nsurveillance is very useful as they keep looking for specific behavior of people \\nlike standing motionless for a long time, stumbling, or napping on benches, etc. \\nWhenever the surveillance system finds a ny unusual activity, it alerts the \\nrespective team, which can stop or help avoid some mishappening at that place.  \\nSome popular uses of video surveillance are:  \\no Facility protections  o Operation monitoring  \\no Parking lots  \\no Traffic monitoring  \\no Shopping patterns  \\n12. E mail & spam filtering  \\nEmails are filtered automatically when we receive any new email, and it is also \\nan example of machine learning. We always receive an important mail in our \\ninbox with the important symbol and spam emails in our spam box, and the \\ntechno logy behind this is Machine learning. Below are some spam filters used \\nby Gmail:  \\no Content Filter  \\no Header filter  \\no General blacklists filter  \\no Rules -based filters  \\no Permission filters  \\nSome machine learning algorithms that are used in email spam filtering and \\nmalwar e detection are  Multi -Layer Perceptron, Decision tree, and Naïve Bayes \\nclassifier . \\n13. Real -Time Dynamic Pricing  \\nWhenever we book an Uber in peak office hours in the morning or evening, we \\nget a difference in prices compared to normal hours. The prices are  hiked due \\nto surge prices applied by companies whenever demand is high. But how these \\nsurge prices are determined & applied by companies. So, the technologies \\nbehind this are AI and machine learning. These technologies solve two main \\nbusiness queries, whi ch are  \\no The reaction of customers on surge prices  \\no Suggesting optimum prices so that no harm of customer losing occurs to \\nbusiness.  14. Gaming and Education  \\nMachine learning technology is widely being used in gaming and education. \\nThere are various gaming an d learning apps that are using AI and Machine \\nlearning. Among these apps,  Duolingo  is a free language learning app, which is \\ndesigned in a fun and interactive way. While using this app, people feel like \\nplaying a game on the phone.  \\nIt collects data from th e user\\'s answer and creates a statical model to determine \\nthat how long a person can remember the word, and before requiring a \\nrefresher, it provides that information.  \\n15. Virtual Assistants  \\nVirtual assistants are much popular in today\\'s world, which are t he smart \\nsoftware embedded in smartphones or laptops. These assistants work as \\npersonal assistants and assist in searching for information that is asked over \\nvoice. A virtual assistant understands human language or natural language \\nvoice commands and perfo rms the task for that user. Some examples of virtual \\nassistants are  Siri, Alexa, Google, Cortana , etc. To start working with these \\nvirtual assistants, first, they need to be activated, and then we can ask \\nanything, and they will answer it. For example, \"What\\'s the date today?\", \"Tell \\nme a joke\", and many more. The technologies used behind Virtual assistants \\nare AI, machine learning, natural language processing, etc . Machine learning \\nalgorithms collect and analyze the data based on the previous involvemen t of \\nthe user and predict data as per the user preferences  \\nWhat is Association Learning?  \\nAssociation learning, often referred to in the context of association rule \\nlearning, is a rule -based  machine learning  method for discovering interesting \\nrelations betw een variables in large databases. It is intended to identify strong \\nrules discovered in databases using some measures of interestingness. This \\nmethod is widely used for market basket analysis, where it is used to find \\nrelationships between items that are f requently bought together.  \\nThe most famous example of association learning is the \"beer and diapers\" \\nstory, where a retail store supposedly discovered through data analysis that \\nmen often bought beer and diapers together. This story is anecdotal, but it \\nillustrates the kind of insights that can be gained from association learning.  Key Concepts in Association Learning  \\nAssociation learning is based on the concept of rules, which are implications of \\nthe form X → Y, where X and Y are disjoint itemsets. A typica l association rule \\nin a market basket analysis might state that if a customer buys bread and \\nbutter (X), they are likely to also buy milk (Y).  \\nThere are three key metrics used in association learning:  \\n\\uf0b7 Support : This is the proportion of transactions in the database that \\ncontain the itemset. In other words, it\\'s the  probability  that a transaction \\ncontains both X and Y .  \\n\\uf0b7 Confidence : This is a measure of the reliability of the inference made by \\nthe rule. For a rule X → Y, it\\'s the probability that a transaction \\ncontaining X also contains Y .  \\n\\uf0b7 Lift: This is the ratio of the observed support to that expected if X and Y \\nwere independent. A lift value greater than 1 indicates that the presence \\nof X increases the likelihood that Y will also be present in the transaction . \\nAssociation Rule Learning Algorithms  \\nThere are several algorithms designed to efficiently find association rules in \\ndata. The most well -known of these are:  \\n\\uf0b7 Apriori Algorithm : This algorithm identifies the itemsets that are \\nfrequently occurring (i.e., hav e support above a user -specified threshold) \\nand then uses these itemsets to generate association rules that meet the \\nconfidence threshold.  \\n\\uf0b7 Frequent Pattern (FP) Growth Algorithm : This is an improvement over \\nthe Apriori  algorithm that uses a special data structure called an FP -tree \\nto store the database in a compressed form. It is often faster than \\nApriori because it reduces the number of database scans.  \\n\\uf0b7 Eclat Algorithm : This algorithm uses a depth -first search strategy to \\ncount the support of itemsets and uses a vertical database format where \\neach item contains the list of transactions that contain that item.  \\nApplications of Association Learning  \\nAssociation learning has applications in various domains, including:  \\n\\uf0b7 Retail : For market basket analysis to understand customer buying habits \\nand to drive sales through promotions and store layout optimizations.  \\uf0b7 Healthcare : For identifying combinations of symptoms and diagnoses \\nthat frequently occur together, which can help in the diagnosis of new \\npatients.  \\n\\uf0b7 Web Usage Mining : For analyzing patterns in web usage data to improve \\nwebsite design and personalized content delivery.  \\n\\uf0b7 Finance : For fraud detection by identifying unusual patterns of \\ntransactions.  \\nClassification:  \\nSupervised Learning : \\nSupervised learning is a process of providing input data as well as correct \\noutput data to the machine learning model. The aim of a supervised learning \\nalgorithm is to  find a mapping function to map the input variable(x) with the \\noutput variable( y). \\nSome examples of Supervised Learning include:  \\n1. It classifies spam Detection by teaching a model of what mail is spam \\nand not spam.  \\n2. Speech recognition where you teach a machine to recognize your \\nvoice.  \\n3. Object Recognition by showing a machine what an object looks like \\nand having it pick that object from among other objects.  \\n \\nClassification:  \\nClassification is defined as the process of recognition, understanding, and \\ngrouping of objects and ideas into preset categories a.k.a “sub-populations. ” \\nWith the help of these pre -categorized training datasets, classification in \\nmachine learning programs leverage a wide range of algorithms to classify \\nfuture datasets into respective and relevant categories.  Classification \\nalgorithms used in machine learning utilize  input training data for the purpose \\nof predicting the likelihood or probability that the data that follows will fall into \\none of the predetermined categories. One of the most common applications of \\nclassification is for filtering emails into “spam ” or “non-spam ”, as used by \\ntoday ’s top email service providers . In short, classification is a form of “pattern \\nrecognition, ”. Here, classification algorithms applied to the training data find \\nthe same pattern (similar number sequences, words or sentiments, and th e \\nlike) in future data sets . \\nThe main objective of classification is to build a model that can accurately \\nassign a label or category to a new observation based on its features. For \\nexample, a classification model might be trained on a dataset of images \\nlabeled as either dogs or cats and then used to predict the class of new, \\nunseen images of dogs or cats based on their features such as color, texture, \\nand shape.  \\nTypes  of Classification  \\nClassification  is of two types:  \\n \\n\\uf0b7 Binary  Classification : In binary  classification,  the goal  is to classify  the \\ninput  into one of two classes  or categories.  Example  – On the basis  of \\nthe given  health  conditions  of a person,  we have  to determine  whether  \\nthe person  has a certain  disease  or not. \\n\\uf0b7 Multiclass  Classification : In multi -class  classification,  the goal  is to \\nclassify  the input  into one of several  classes  or categories.  For Example  \\n– On the basis  of data  about  different  species  of flowers,  we have  to \\ndetermine  which  specie  our observation  belongs  to. \\n  \\nTypes  of classi fication  algorithms  \\n \\nThere  are various  types  of classifiers.  Some  of them  are :  \\n \\nLinear  Classifiers:  Linear  models  create  a linear  decision  boundary  between  \\nclasses.  They  are simple  and computationally  efficient.  Some  of the \\nlinear  classification  models  are as follows:   \\n\\uf0b7 Logistic  Regression  \\n\\uf0b7 Support  Vector  Machines  having  kernel  = ‘linear ’ \\n\\uf0b7 Single -layer  Perceptron  \\n\\uf0b7 Stochastic  Gradient  Descent  (SGD)  Classifier  \\nNon -linear  Classifiers:  Non -linear  models  create  a non-linear  decision  \\nboundary  between  classes.  They  can capture  more  complex  relationships  \\nbetween  the input  features  and the target  variable.  Some  of the non-\\nlinear  classification  models  are as follows:   \\n\\uf0b7 K-Nearest  Neighbours  \\n\\uf0b7 Kernel  SVM  \\n\\uf0b7 Naive  Bayes \\n\\uf0b7 Decision  Tree  Classification  \\n\\uf0b7 Ensemble  learning  classifiers:   \\n\\uf0b7 Random  Forests,   \\n\\uf0b7 AdaBoost,   \\n\\uf0b7 Bagging  Classifier,   \\n\\uf0b7 Voting  Classifier,   \\n\\uf0b7 ExtraTrees  Classifier  \\n\\uf0b7 Multi -layer  Artificial  Neural  Networks  \\nLearners in Classification Problems:  \\nIn the classification problems, there are two types of learners:  \\n1. Lazy Learners:  Lazy Learner firstly stores the training dataset and wait until it \\nreceives the test dataset. In Lazy learner case, classification is done on the basis \\nof the most related data stored in the training dataset. It takes less time in \\ntraining but more time for predictions.  \\nExample:  K-NN algorithm, Case -based reasoning  \\n2. Eager Learners: Eager Learners develop a classification model based on a \\ntraining dataset before receiving a test dataset. Opposite to Lazy learners, Eager \\nLearner takes more time in l earning, and less time in \\nprediction.  Example:  Decision Trees, Naïve Bayes, ANN.  \\nUse cases of Classification Algorithms  \\nClassification algorithms can be used in different places. Below are some popular use \\ncases of Classification Algorithms:  \\no Email Spam Detection  \\no Speech Recognition  \\no Identifications of Cancer tumor cells.  \\no Drugs Classification  \\no Biometric Identification, etc.  \\nRegression Analysis in Machine learning  \\nRegression analysis is a statistical method to model the relationship between a \\ndependent (target) and independent (predictor) variables with one or more \\nindependent variables. More specifically, Regression analysis helps us to \\nunderstand how the value of the dependent variable is changing corresponding \\nto an independent variable when other ind ependent variables are held fixed. It \\npredicts continuous/real values such as  temperature, age, salary, price , etc. \\nWe can understand the concept of regression analysis using the below example:  \\nExample:  Suppose there is a marketing company A, who does vari ous \\nadvertisement every year and get sales on that. The below list shows the \\nadvertisement made by the company in the last 5 years and the corresponding \\nsales:   \\nNow, the company wants to do the advertisement of $200 in the year 2019  and \\nwants to know the prediction about the sales for this year . So to solve such type \\nof prediction problems in machine learning, we need regression analysis.  \\nRegression is a  supervised learning technique  which helps in finding the \\ncorrelation between variables and enables us to predict the continuous output \\nvariable based on the one or more predictor variables. It is mainly used \\nfor prediction, forecasting, time series modeling, and determining the causal -\\neffect relationship between variables . \\nIn Regression, we plot a graph between the variables which best fits the given \\ndatapoints, using this plot, the machine learning model can make predictions \\nabout the data. In simple words,  \"Regression shows a line or cu rve that passes \\nthrough all the datapoints on target -predictor graph in such a way that the \\nvertical distance between the datapoints and the regression line is \\nminimum.\"  The distance between datapoints and line tells whether a model has \\ncaptured a strong relationship or not.  \\nSome examples of regression can be as:  \\no Prediction of rain using temperature and other factors  \\no Determining Market trends  \\no Prediction of road accidents due to rash driving.  \\n \\nTypes of regression  \\nRegression models will obediently produce an answer, but can hide \\ninaccuracies or oversimplifications, Kramer agreed. And a wrong prediction is \\noften worse than no prediction. It\\'s important to understand that one \\napproach might work better than others, depending on the problem.  \\n\"I\\'ve been known t o use the tip of the blade in my Swiss Army knife and make \\nit work when the screwdriver would be more effective. Similarly, we often see \\nanalysts apply the type of regression they know, even when it\\'s not the best \\nsolution,\" Kramer said.  \\nHere are five type s of regression and what they do best.  \\n\\uf0b7 Linear regression  models assume a linear relationship between a \\ntarget and predictor variables. The model aims to fit a straight line \\nrepresenting the data points. Linear regression is useful when there is \\na linear relationship between the variables, such as predicting sales \\nbased on advertising expenditure or estimating the impact of price \\nchanges on demand.  \\n\\uf0b7 Logistic regression  is used when the target variable is binary or has \\ntwo classes. It models the probability of an event occurring -- for \\nexample, yes/no or success/failure -- based on predictor variables. \\nLogistic regression is commonly used in business contexts for binary \\nclassification tasks such as customer churn prediction or transaction \\nfraud detection.  \\n\\uf0b7 Polynomial regression  extends linear regression by incorporating \\npolynomial concepts such as quadratic and cubic equations to format \\nthe predictor variables and capture cases where a straightforward \\nlinear relationship doesn\\'t exist, such as estimating the im pact of ad \\nspending on sales.  \\n\\uf0b7 Time series regression , such as autoregressive integrated moving \\naverage, or ARIMA, models, incorporate time dependencies and \\ntrends to forecast future values based on past observations. These \\nare useful for business applicati ons such as sales forecasting, demand \\nprediction and stock market analysis.  \\n\\uf0b7 Support vector regression  (SVR) is a regression version of support \\nvector machines and is particularly suitable for handling nonlinear \\nrelationships in high -dimensional spaces. SVR  can be applied to tasks \\nsuch as financial market prediction, customer churn forecasting or \\npredicting customer lifetime value.  \\nApplications of regression  \\nKramer offered the following specific applications of regression frequently \\nused in business:  \\n\\uf0b7 Sales f orecasting.  Predicting future sales based on historical sales \\ndata, marketing expenditure, seasonality, economic factors and other \\nrelevant variables.  \\n\\uf0b7 Customer lifetime value prediction.  Estimating the potential value of \\na customer over the customer\\'s enti re relationship with the company \\nbased on past purchase history, demographics and behavior.  \\uf0b7 Churn prediction.  Predicting the likelihood of customers leaving the \\ncompany\\'s services based on their usage patterns, customer \\ninteractions and other related featu res. \\n\\uf0b7 Employee performance prediction.  Predicting the performance of \\nemployees based on various factors such as training, experience and \\ndemographics.  \\n\\uf0b7 Financial performance analysis.  Understanding the relationship \\nbetween financial metrics (e.g., revenue, p rofit) and key drivers (e.g., \\nmarketing expenses, operational costs).  \\n\\uf0b7 Risk analysis and fraud detection.  Predicting the likelihood of events \\nsuch as credit defaults, insurance claims, or fraud based on historical \\ndata and risk indicators.  \\n\\uf0b7 Maintenance prediction.  Predicting time to failure of critical parts \\nand machinery.  \\nAdvantages and disadvantages of regression  \\nStewart said one of the main advantages of regression models is that they are \\nsimple and easy to understand. They are very transparent models , and it is \\neasy to clearly explain how the model makes a prediction . \\nAnother advantage is that regression models have been used in industries for a \\nlong time and are well understood. For example, generalized linear models are \\nheavily used within the actua rial profession, and their use is well established. \\n\"The models are well understood by regulatory bodies, making it simple to \\nhave informed discussions about model implementation and associated risk, \\ngovernance and oversight,\" Stewart said.  \\nTheir simplicit y, however, is also their limitation, he said. Regression models \\nrely on several assumptions that rarely apply in real -world scenarios, and they \\ncan only handle simple relationships between predictors and the predicted \\nvalue. Therefore, other machine learn ing models usually outperform \\nregression models.  In Khadilkar\\'s view, regression provides the greatest value as a quantitative \\nmeasurement, interpolation and prediction tool -- and is incredibly good at \\nthis. \"Its properties are well known, and we have gre at ways of quantifying our \\nconfidence about our predictions as well,\" he said. For example, one can \\npredict stock market prices with a specific range of possible variations around \\nthe predicted quantity.  \\nHowever, there are many applications where regressio n is not well suited. \"For \\nexample, it is less useful for recognizing faces from images. Also, it is not a fit \\nwhen trying to mine data for pattern recognition or automating decisions,\" \\nKhadilkar said.  \\n\"The key disadvantage of regression is possibly the fa ct that it only gives us a \\nprediction of the quantity of interest without suggesting what you should do \\nwith the information,\" Khadilkar explained. \"That is up to the human to \\ndecide.\"  \\nWhat is Unsupervised  learning?  \\n \\nUnsupervised  learning  is a type  of machine  learning  that  learns  from  \\nunlabeled  data.  This means  that  the data  does  not have  any pre-existing  \\nlabels  or categories.  The goal  of unsupervised  learning  is to discover  patterns  \\nand relationships  in the data  witho ut any explicit  guidance.  \\nUnsupervised  learning  is the training  of a machine  using  information  that  is \\nneither  classified  nor labeled  and allowing  the algorithm  to act on that  \\ninformation  without  guidance.  Here  the task of the machine  is to group  \\nunsorted  information  according  to similarities,  patterns,  and differences  \\nwithout  any prior  training  of data.   \\nUnlike  supervised  learning,  no teacher  is provided  that  means  no training  will \\nbe given  to the machine.  Therefore  the machine  is restricted  to find the \\nhidden  structure  in unlabeled  data  by itself.   \\nYou can use unsupervised  learning  to examine  the animal  data  that  has been  \\ngathered  and distinguish  between  several  groups  according  to the traits  and \\nactions  of the animals.  These  groupings  might  correspond  to various  animal  \\nspecies,  providing  you to categorize  the creatures  without  depending  on \\nlabels  that  already  exist.   \\n \\nKey Points  \\n\\uf0b7 Unsupervised  learning  allows  the model  to discover  patterns  and \\nrelationships  in unlabeled  data.  \\n\\uf0b7 Clustering  algorithms  group  similar  data  points  together  based  on \\ntheir  inherent  characteristics.  \\n\\uf0b7 Feature  extraction  captures  essential  information  from  the data,  \\nenabling  the model  to make  meaningful  distinctions.  \\n\\uf0b7 Label  association  assigns  categories  to the clusters  based  on the \\nextracted  patterns  and characteristics . \\nExample  \\nImagine  you have  a machine  learning  model  trained  on a large  dataset  of \\nunlabeled  images,  containing  both  dogs  and cats.  The model  has never  seen  \\nan image  of a dog or cat before,  and it has no pre-existing  labels  or categories  \\nfor these  animals.  Your  task is to use unsupervised  learning  to identify  the \\ndogs  and cats in a new,  unseen  image.  \\nFor instance , suppose  it is given  an image  having  both  dogs  and cats which  it \\nhas never  seen.   \\nThus  the machine  has no idea  about  the features  of dogs  and cats so we can’t  \\ncategorize  it as ‘dogs  and cats ‘. But it can categorize  them  according  to their  \\nsimilarities,  patterns,  and differences,  i.e., we can easily  categorize  the above  \\npicture  into two parts.  The first may  contain  all pics having  dogs  in them  and \\nthe second  part  may  contain  all pics having  cats in them.  Here  you didn’t  \\nlearn  anything  before,  which  means  no training  data  or examples.   \\nIt allows  the model  to work  on its own  to discover  patterns  and information  \\nthat was previously  undetected.  It mainly  deals  with  unlabelled  data.  \\nTypes  of Unsupervised  Learning  \\nUnsupervised  learning  is classified  into two categories  of algorithms:   \\n\\uf0b7 Clustering : A clustering  problem  is where  you want  to discover  the \\ninherent  groupings  in the data,  such  as grouping  customers  by \\npurchasing  behavior.  \\n\\uf0b7 Association : An association  rule learning  problem  is where  you want  \\nto discover  rules  that  describe  large  portions  of your  data,  such  as \\npeople  that buy X also tend  to buy Y. \\n \\nClustering  \\nClustering  is a type  of unsupervised  learning  that  is used  to group  similar  data  \\npoints  together.  Clusterin g algorithms  work  by iteratively  moving  data  points  \\ncloser  to their  cluster  centers  and further  away  from  data  points  in other  \\nclusters.  \\n1. Exclusive  (partitioning)  \\n2. Agglomerative  \\n3. Overlapping  \\n4. Probabilistic  \\n5.  \\nClustering  Types: - \\n1. Hierarchical  clustering  \\n2. K-means  clustering  \\n3. Principal  Component  Analysis  \\n4. Singular  Value  Decomposition  \\n5. Independent  Component  Analysis  \\n6. Gaussian  Mixture  Models  (GMMs)  \\n7. Density -Based  Spatial  Clustering  of Applications  with  Noise  \\n(DBSCAN)  \\nAssociation  rule learning : \\nAssociation  rule learning  is a type  of unsupervised  learning  that  is used  to \\nidentify  patterns  in a data.  Association  rule learning  algorithms  work  by \\nfinding  relationships  between  different  items  in a dataset.  \\nSome  commo n association  rule learning  algorithms  include:  \\n\\uf0b7 Apriori  Algorithm  \\n\\uf0b7 Eclat  Algorithm  \\n\\uf0b7 FP-Growth  Algorithm  \\nEvaluating  Non -Supervised  Learning  Models  \\nEvaluating  non-supervised  learning  models  is an important  step  in ensuring  \\nthat  the model  is effective  and useful.  However,  it can be more  challenging  \\nthan  evaluating  supervised  learning  models,  as there  is no ground  truth  data  \\nto compare  the model’s  predictions  to. There  are a number  of different  metrics  that  can be used  to evaluate  non-\\nsupervised  learning  mod els, but some  of the most  common  ones  include:  \\n\\uf0b7 Silhouette  score:  The silhouette  score  measures  how  well each  data  \\npoint  is clustered  with  its own  cluster  members  and separated  from  \\nother  clusters.  It ranges  from  -1 to 1, with  higher  scores  indicating  \\nbette r clustering.  \\n\\uf0b7 Calinski -Harabasz  score:  The Calinski -Harabasz  score  measures  the \\nratio  between  the variance  between  clusters  and the variance  within  \\nclusters.  It ranges  from  0 to infinity,  with  higher  scores  indicating  \\nbetter  clustering.  \\n\\uf0b7 Adjusted  Rand  index:  The adjusted  Rand  index  measures  the \\nsimilarity  between  two clusterings.  It ranges  from  -1 to 1, with  \\nhigher  scores  indicating  more  similar  clusterings.  \\n\\uf0b7 Davies -Bouldin  index:  The Davies -Bouldin  index  measures  the \\naverage  similarity  between  clusters.  It ranges  from  0 to infinity,  with  \\nlower  scores  indicating  better  clustering.  \\n\\uf0b7 F1 score:  The F1 score  is a weighted  average  of precision  and \\nrecall,  which  are two metrics  that  are commonly  used  in supervised  \\nlearning  to evaluate  classification  models.  Howe ver, the F1 score  can \\nalso be used  to evaluate  non-supervised  learning  models,  such  as \\nclustering  models.  \\nApplication  of Unsupervised  learning  \\nNon -supervised  learning  can be used  to solve  a wide  variety  of problems,  \\nincluding:  \\n\\uf0b7 Anomaly  detection:  Unsupervised  learning  can identify  unusual  \\npatterns  or deviations  from  normal  behavior  in data,  enabling  the \\ndetection  of fraud,  intrusion,  or system  failures.  \\n\\uf0b7 Scientific  discovery:  Unsupervised  learning  can uncover  hidden  \\nrelationships  and patterns  in scientific  data,  leading  to new  \\nhypotheses  and insights  in various  scientific  fields.  \\n\\uf0b7 Recommendation  systems:  Unsupervised  learning  can identify  \\npatterns  and similarities  in user  behavior  and preferences  to \\nrecommend  products,  movies,  or music that align  with  their  \\ninterests.  \\n\\uf0b7 Customer  segmentation:  Unsupervised  learning  can identify  groups  \\nof customers  with  similar  characteristics,  allowing  businesses  to \\ntarget  marketing  campaigns  and improve  customer  service  more  \\neffectively.  \\uf0b7 Image  analysis : Unsupervised  learning  can group  images  based  on \\ntheir  content,  facilitating  tasks  such  as image  classification,  object  \\ndetection,  and image  retrieval.  \\nAdvantages  of Unsupervised  learning  \\n\\uf0b7  It does  not require  training  data  to be labeled.  \\n\\uf0b7 Dimensionality  reduction  can be easily  accomplished  using  \\nunsupervised  learning.   \\n\\uf0b7 Capable  of finding  previously  unknown  patterns  in data.  \\n\\uf0b7 Unsupervised  learning  can help  you gain  insights  from  unlabeled  \\ndata  that you might  not have  been  able  to get otherwise.  \\n\\uf0b7 Unsupervised  learning  is good  at finding  patterns  and relationships  \\nin data  without  being  told what  to look  for. This can help  you learn  \\nnew  things  about  your  data.  \\nDisadvantages  of Unsupervised  learning  \\n\\uf0b7 Difficult  to measure  accuracy  or effectiveness  due to lack of \\npredefined  answers  during  training.   \\n\\uf0b7 The results  often  have  lesser  accuracy.  \\n\\uf0b7 The user  needs  to spend  time  interpreting  and label  the classes  \\nwhich  follow  that  classification.  \\n\\uf0b7 Unsupervised  learning  can be sensitive  to data  quality,  including  \\nmissing  values,  outliers,  and noisy  data.  \\n\\uf0b7 Without  labeled  data,  it can be difficult  to evaluate  the performance  \\nof unsupervised  learning  models,  making  it challenging  to assess \\ntheir effectiveness.  \\n \\n    Supervised  vs. Unsupervised  Machine  Learning  \\n \\nParameters            Supervised  \\nmachine  learning              Unsupervised  \\nmachine  learning  \\nInput  Data    Algorithms  are trained  \\nusing  labeled  data.  Algorithms  are used against  \\ndata that is not labeled  \\nComputational  \\nComplexity    Simpler  method   Computationally  complex  \\nAccuracy  Highly  accurate  Less accurate   Parameters            Supervised  \\nmachine  learning              Unsupervised  \\nmachine  learning  \\nNo. of classes  No. of classes  is known  No. of classes  is not known  \\nData  Analysis  Uses  offline  analysis  Uses  real-time analysis  of \\ndata \\nAlgorithms  used  Linear  and Logistics  \\nregression,  Random  \\nforest,  \\nSupport  Vector  Machine,  \\nNeural  Network,  etc. K-Means  clustering,  \\nHierarchical  clustering,   \\nApriori  algorithm,  etc. \\nOutput   Desired  output  is given.  Desired  output  is not given.  \\nTraining  data   Use training  data to infer  \\nmodel.  No training  data is used.  \\nComplex  model   It is not possible  to learn  \\nlarger  and more  complex  \\nmodels  than with \\nsupervised  learning.  It is possible  to learn  larger  \\nand more  complex  models  \\nwith unsupervised  learning.  \\nModel   We can test our model.  We can not test our model.  \\nCalled  as Supervised  learning  is \\nalso called  classification.  Unsupervised  learning  is \\nalso called  clustering.  \\nExample   Example:  Optical  \\ncharacter  recognition.  Example:  Find a face in an \\nimage.  \\n \\nWhat is Reinforcement Learning?  \\n\\uf0b7 Reinforcement Learning is a feedback -based Machine learning technique \\nin which an agent learns to behave in an environment by performing the \\nactions and seeing the results of actions. For each good action, the agent gets positive feedback, and for each bad action, the agent gets negative \\nfeedback or penalt y. \\n\\uf0b7 In Reinforcement Learning, the agent learns automatically using \\nfeedbacks without any labeled data, unlike  supervised learning.  \\n\\uf0b7 Since there is no labeled data, so the agent is bound to learn by its \\nexperience only.  \\n\\uf0b7 RL solves a specific type of problem where decision making is sequential, \\nand the goal is long -term, such as  game -playing, robotics , etc.  \\n\\uf0b7 The agent interacts with the environment and explores it by itself. The \\nprimary goal of an agent in reinforcement learning is to improve the \\nperformance by getting the maximum positive rewards.  \\n\\uf0b7 The agent learns with the process of hit and trial, and based on the \\nexperience, it learns to perform the task in a better way. Hence, we can \\nsay t hat \"Reinforcement learning is a type of machine learning method \\nwhere an intelligent agent (computer program) interacts with the \\nenvironment and learns to act within that.\"  How a Robotic dog learns the \\nmovement of his arms is an example of Reinforcement learning.  \\n\\uf0b7 It is a core part of  Artificial intelligence , and all  AI agent  works on the \\nconcept of reinforcement learning. Her e we do not need to pre -program \\nthe agent, as it learns from its own experience without any human \\nintervention.  \\n\\uf0b7 Example:  Suppose there is an AI agent present within a maze \\nenvironment, and his goal is to find the diamond. The agent interacts with \\nthe envir onment by performing some actions, and based on those actions, \\nthe state of the agent gets changed, and it also receives a reward or \\npenalty as feedback.  \\n\\uf0b7 The agent continues doing these three things ( take action, change \\nstate/remain in the same state, and get feedback ), and by doing these \\nactions, he learns and explores the environment.  \\n\\uf0b7 The agent learns that what actions lead to positive feedback or rewards \\nand what actions lead to negative feedback penalty. As a positive reward, \\nthe agent gets a positive p oint, and as a penalty, it gets a negative point.   \\n \\nKey Features of Reinforcement Learning  \\n\\uf0b7 In RL, the agent is not instructed about the environment and what actions \\nneed to be taken.  \\n\\uf0b7 It is based on the hit and trial process.  \\n\\uf0b7 The agent takes the next action and changes states according to the \\nfeedback of the previous action.  \\n\\uf0b7 The agent may get a delayed reward.  \\n\\uf0b7 The environment is stochastic, and the agent needs to explore it to reach \\nto get the maximum positive rewards.  \\nApproaches to implement Reinforce ment Learning  \\nThere are mainly three ways to implement reinforcement -learning in ML, which are:  \\n\\uf0b7 Value -based:  \\nThe value -based approach is about to find the optimal value function, which is \\nthe maximum value at a state under any policy. Therefore, the agent expects \\nthe long -term return at any state(s) under policy π.  \\n\\uf0b7 Policy -based:  \\nPolicy -based approach is to find the optimal policy for the maximum future \\nrewards without using the value function. In this approach, the agent tries to \\napply such a policy that th e action performed in each step helps to maximize \\nthe future reward.  \\nThe policy -based approach has mainly two types of policy:  \\no Deterministic:  The same action is produced by the policy (π) at any \\nstate.  \\no Stochastic:  In this policy, probability determines the  produced action.  \\n\\uf0b7 Model -based:  In the model -based approach, a virtual model is created for the \\nenvironment, and the agent explores that environment to learn it. There is no \\nparticular solution or algorithm for this approach because the model \\nrepresentation  is different for each environment.  \\n \\nhttps://www.javatpoint.com/reinforcement -learning  \\nunit-2 \\nDimensionality Reduction:  \\nIntroduction:  \\nDimensionality reduction is a technique used to reduce the number of features in a \\ndataset while retaining as much of the important information as possible. In other words, \\nit is a process of transforming high -dimensional data into a lower -dimensional space that \\nstill preserves the essence of the original data . \\nIn machine learning, high -dimensional data refers to data with a large number of features \\nor variables. The curse of dimensionality is a common problem in machine learning, where \\nthe performance of the model deteriorates as the number of features increases. This is \\nbecause the complexity of the model increases with the number of features, and it \\nbecomes more difficult to find a good solution. In addition, high -dimensional data can also \\nlead to overfitting, where the model fits the training data too  closely and does not \\ngeneralize well to new data.  \\nDimensionality reduction can help to mitigate these problems by reducing the complexity \\nof the model and improving its generalization performance. There are two main \\napproaches to dimensionality reduction:  feature selection and feature extraction.  Feature Selection:  \\nFeature selection involves selecting a subset of the original features that are most relevant \\nto the problem at hand. The goal is to reduce the dimensionality of the dataset while \\nretaining the most important features. There are several methods for feature selection, \\nincluding filter methods, wrapper methods, and embedded methods. Filter methods rank \\nthe features based on their relevance to the target variable, wrapper methods use the \\nmodel perfo rmance as the criteria for selecting features, and embedded methods \\ncombine feature selection with the model training process.  \\nFeature Extraction:  \\nFeature extraction involves creating new features by combining or transforming the \\noriginal features. The goa l is to create a set of features that captures the essence of the \\noriginal data in a lower -dimensional space. There are several methods for feature \\nextraction, including principal component analysis (PCA), linear discriminant analysis \\n(LDA), and t -distribu ted stochastic neighbo ur embedding (t -SNE). PCA is a popular \\ntechnique that projects the original features onto a lower -dimensional space while \\npreserving as much of the variance as possible.  \\nFeature  selection:  In this, we try to find a subset of the original set of variables, or \\nfeatures, to get a smaller subset which can be used to model the problem. It usually \\ninvolves three ways:  \\n1. Filter  \\n2. Wrapper  \\n3. Embedded  \\n\\uf0b7 Feature  extraction:  This reduces the data in a high dimensional space to a \\nlower dimension space , i.e. a space with lesser no. of dimensions.  \\n \\nForward selection  \\n \\nForward selection is a feature selection technique commonly used in machine learning to \\nbuild a model by iteratively adding features to the model one at a time. The goal is to \\nidentify the most relevant subset of features that improves the model\\'s performance.  \\nForward selection is a feature selection technique used in machine learning to iteratively \\nbuild a model by adding one feature at a time to identify the most relevant subset of \\nfeature s. The goal is to improve the model\\'s performance by selecting features that \\ncontribute the most to predictive accuracy. This process involves sequentially evaluating \\nand adding features based on their individual contribution to the model.  \\nHere\\'s a step -by-step explanation of forward selection:  \\n1. Start  with  an Empty  Model:  \\n\\uf0b7 Begin with an empty set of features.  \\n2. Feature  Evaluation:  \\n\\uf0b7 Train the model using each individual feature separately.  \\n\\uf0b7 Evaluate the model\\'s performance using a chosen metric (e.g., accur acy, \\nprecision, recall, F1 -score).  3. Select  the Best  Feature:  \\n\\uf0b7 Identify the feature that contributes the most to the model\\'s performance, \\nbased on the evaluation metric.  \\n\\uf0b7 This could involve comparing the performance of different models, each built \\nwith a singl e additional feature.  \\n4. Add the Best  Feature  to the Model:  \\n\\uf0b7 Include the selected feature in the model.  \\n5. Iterative  Process:  \\n\\uf0b7 Repeat steps 2 -4 for the current model, which now includes the selected \\nfeature.  \\n\\uf0b7 In each iteration, evaluate the performance of the model  with the currently \\nselected features plus each remaining feature.  \\n6. Stopping  Criteria:  \\n\\uf0b7 Define a stopping criterion (e.g., reaching a certain performance threshold, \\nincluding a maximum number of features, etc.).  \\n7. Final  Model:  \\n\\uf0b7 Stop the process when the stoppin g criterion is met.  \\n\\uf0b7 The final model includes the selected subset of features.  \\nForward selection is a greedy algorithm, making locally optimal choices at each step without \\nconsidering the global impact on future decisions. This approach is computationally \\nefficient, especially when dealing with a large number of features. However, it may not \\nalways result in the globally optimal subset of features.  \\nIt\\'s important to note that the performance metric used for evaluation plays a crucial role in \\nthe selection pr ocess. Different metrics may lead to the identification of different subsets of \\nfeatures.  \\nOverall, forward selection is a practical and straightforward method for feature selection, \\nand it can be combined with cross -validation techniques for a more robust evaluation of the \\nmodel\\'s performance.  \\n \\nPrincipal Component Analysis:  \\nPrincipal Component Analysis is an unsupervised learning algorithm that is used for \\nthe dimensionality reduction in  machine le arning . It\\'s a method that rearranges related \\ndata points into a new set of independent data points using a mathematical technique \\ncalled orthogonal transformation.  These new transformed features are called \\nthe Principal Components . It is one of the popular tools that is used for exploratory \\ndata analysis and predictive modeling. It is a technique to draw strong patterns from \\nthe given dataset by reducing the variances.  \\nPCA generally tries to find the lower -dimensional surface to pr oject the high -\\ndimensional data.  PCA works by considering the variance of each attribute because the high attribute \\nshows the good split between the classes, and hence it reduces the dimensionality. \\nSome real -world applications of PCA are  image processing,  movie recommendation \\nsystem, optimizing the power allocation in various communication channels.  It is \\na feature extraction technique, so it contains the important variables and drops the \\nleast important variable.  \\nPrincipal Components in PCA  \\nAs described a bove, the transformed new features or the output of PCA are the \\nPrincipal Components. The number of these PCs are either equal to or less than the \\noriginal features present in the dataset. Some properties of these principal \\ncomponents are given below:  \\no The principal component must be the linear combination of the original features.  \\no These components are orthogonal, i.e., the correlation between a pair of variables is \\nzero.  \\no The importance of each component decreases when going to 1 to n, it means the 1 PC \\nhas the most importance, and n PC will have the least importance.  \\nSteps for PCA algorithm  \\n \\nGetting the dataset  \\nFirstly, we need to take the input dataset and divide it into two subparts X and Y , where X is the \\ntraining set, and Y is the validation set.  \\nRepresenting data into a structure  \\nNow we will represent our dataset into a structure. Such as we will represent the two -dimensional \\nmatrix of independent variable X. Here each row corresponds to the data items, and the column \\ncorresponds to the Features. The number of columns is the dimensions of the dataset.  \\nStandardizing the data  \\nIn this step, we will standardize our dataset. Such as in a particular column, the features with high \\nvariance are more important compared to the features with lower variance.  \\nIf the importance of features is independent of the variance of the feature, then we will divide each \\ndata item in a column with the standard deviation of the column. Here we will name the matrix as Z.  \\nCalculating the Covariance of Z  \\nTo calculate the covar iance of Z, we will take the matrix Z, and will transpose it. After transpose, we \\nwill multiply it by Z. The output matrix will be the Covariance matrix of Z.  \\nCalculating the Eigen Values and Eigen Vectors  \\nNow we need to calculate the eigenvalues and eigen vectors for the resultant covariance matrix Z. \\nEigenvectors or the covariance matrix are the directions of the axes with high information. And the \\ncoefficients of these eigenvectors are defined as the eigenvalues.  \\nSorting the Eigen Vectors  \\nIn this step, we  will take all the eigenvalues and will sort them in decreasing order, which means from \\nlargest to smallest. And simultaneously sort the eigenvectors accordingly in matrix P of eigenvalues. \\nThe resultant matrix will be named as P*.  Calculating the new feat ures Or Principal Components  \\nHere we will calculate the new features. To do this, we will multiply the P* matrix to the Z. In the \\nresultant matrix Z*, each observation is the linear combination of original features. Each column of \\nthe Z* matrix is independ ent of each other.  \\nRemove less or unimportant features from the new dataset.  \\nThe new feature set has occurred, so we will decide here what to keep and what to remove. It \\nmeans, we will only keep the relevant or important features in the new dataset, and un important \\nfeatures will be removed out.  \\nApplications of Principal Component Analysis  \\nNow that you know the meaning of PCA and the overall steps in its functioning, let us consider \\nits key applications. Due to the ubiquity of data modeling operations, dimen sionality reduction \\nis used in many fields. This includes:  \\n1. Biology and medicine  \\nThe discipline of neuroscience employs spike -triggered covariance analysis, a type of principal \\ncomponents analysis. PCA assists in identifying the stimulus properties that increase the \\nprobability of a neuron causing an “action ” response.  \\n \\n2. Financial services  \\nPCA reduces the number of dimensions in a complicated financial problem. Let us assume that \\nan investment banker ’s portfolio comprises 150 securities. To quantitative ly analyze these \\nequities, they will need a 150 -by-150 correlation matrix, which renders the issue extremely \\ncomplex. Nevertheless, PCA may assist in extracting 15 principal components that best define \\nthe stock variance. This would simplify the problem wh ile additionally detailing the fluctuations \\nof each of the 150 equities.  \\n3. Facial recognition technology  \\nAn array of eigenvectors employed for the computer vision challenge of detecting human \\nfaces is called an eigenface. PCA is central to the eigenfaces method, as it generates the \\ncollection of possible faces that are likely to occur. Principal component analysis decreases the \\nstatistical complexity of face image depiction while maintaining its essential characteristics. \\nThis is crucial for facial recogni tion technology.  \\n4. Image compression  Consider that we are given an extensive collection of 64×64 images of human features. Now, \\nwe wish to portray and retain pictures with significantly lower dimensions. Using the PCA \\nconcept, photographs can be compresse d and stored in smaller, similarly precise files. \\nHowever, it should be noted that reconstructing an image requires further computations.  \\nTypes OF Regularization:  \\nWhat is regularization in machine learning?  \\nRegularization is a machine -learning approach that prevents overfitting by including a penalty \\nterm into the model\\'s loss function. Regularization has two objectives: to lessen a model\\'s \\ncomplexity and to improve its ability to generalize to new inputs. Different penalty terms are \\nadded to the loss fu nction using numerous regularization methods, including L1 and L2 \\nregularization. In contrast to L2 regularization, which adds a punishment term based on the \\nsquares of the parameters, L1 regularization adds a penalty term based on the absolute values \\nof the model\\'s parameters. Regularization decreases the chance of overfitting and helps keep \\nthe model\\'s parameters from going out of control, both of which can enhance the model\\'s \\nperformance on untested data  \\nTypes of regularization  \\n1. L1 regularization  \\nL1 regularization, also known as Lasso regularization, adds the sum of the absolute values of \\nthe model’s coefficients to the loss function. It encourages sparsity in the model by \\nshrinking some coefficients to precisely zero. This has the effect of performin g feature \\nselection, as the model can effectively ignore irrelevant or less important features. L1 \\nregularization is particularly useful when dealing with high -dimensional datasets with \\ndesired feature selection.  \\nMathematically, the L1 regularization term can be written as:  \\nL1 regularization  = λ * Σ|wi|  \\nHere,  λ is the regularization parameter that controls the strength of \\nregularization,  wi represents the individual model coefficients and the sum is taken over all \\ncoefficients.  \\n2. L2 regularization  \\nL2 regul arization, also known as Ridge regularization, adds the sum of the squared values of \\nthe model’s coefficients to the loss function. Unlike L1 regularization, L2 regularization does \\nnot force the coefficients to be exactly zero but instead encourages them t o be small. L2 regularization can prevent overfitting by spreading the influence of a single feature across \\nmultiple features. It is advantageous when there are correlations between the input \\nfeatures.  \\nMathematically, the L2 regularization term can be writ ten as:  \\nL2 regularization  = λ * Σ(wi^2)  \\nSimilar to L1 regularization,  λ is the regularization parameter, and  wi represents the model \\ncoefficients. The sum is taken over all coefficients, and the squares of the coefficients are \\nsummed.  \\nThe choice between L1  and L2 regularization depends on the specific problem and the \\ncharacteristics of the data. For example, L1 regularization produces sparse models, which \\ncan be advantageous when feature selection is desired. L2 regularization, on the other \\nhand, encourages  small but non -zero coefficients and can be more suitable when there are \\nstrong correlations between features.  \\nIn practice, a combination of both L1 and L2 regularization, known as Elastic Net \\nregularization, is often used to benefit from the strengths of both techniques. Elastic Net \\nregularization adds a linear combination of L1 and L2 regularization terms to the loss \\nfunction, controlled by two parameters: α and λ. This allows for simultaneous feature \\nselection and coefficient shrinkage.  \\nLinear Discriminant Analysis:  \\nLinear Discriminant Analysis (LDA) is one of the commonly used dimensionality reduction \\ntechniques in machine learning to solve more than two -class classification problems. It is \\nalso known as Normal Discriminant Analysis (NDA) or Di scriminant Function Analysis (DFA).  \\nThis can be used to project the features of higher dimensional space into lower -\\ndimensional space in order to reduce resources and dimensional costs.  Although the \\nlogistic regression algorithm is limited to only two -class, linear Discriminant analysis is \\napplicable for more than two classes of classification problems.  \\nLinear Discriminant analysis is one of the most popular dimensionality reduction techniques \\nused for supervised classification problems in machine learning . It is also considered a pre -\\nprocessing step for modeling differences in ML and applications of pattern classification.  \\nWhenever there is a requirement to separate two or more classes having multiple \\nfeatures efficiently, the Linear Discriminant Analysis m odel is considered the most \\ncommon technique to solve such classification problems. For e.g., if we have two \\nclasses with multiple features and need to separate them efficiently. When we classify \\nthem using a single feature, then it may show overlapping.   \\nTo overcome the overlapping issue in the classification process, we must increase the \\nnumber of features regularly.  \\nHow Linear Discriminant Analysis (LDA) works?  \\nLinear Discriminant analysis is used as a dimensionality reduction technique in machine \\nlearn ing, using which we can easily transform a 2 -D and 3 -D graph into a 1 -\\ndimensional plane.  \\nLet\\'s consider an example where we have two classes in a 2 -D plane having an X -Y \\naxis, and we need to classify them efficiently. As we have already seen in the above \\nexample that LDA enables us to draw a straight line that can completely separate the \\ntwo classes of the data points. Here, LDA uses an X -Y axis to create a new axis by \\nseparating them using a straight line and projecting data onto a new axis.  \\nHence, we can maximize the separation between these classes and reduce the 2 -D \\nplane into 1 -D. \\n \\nTo create a new axis, Linear Discriminant Analysis uses the following criteria:  \\no It maximizes the distance between means of two classes.  \\no It minimizes the variance within the individual class.  \\nUsing the above two conditions, LDA generates a new axis in such a way that it can \\nmaximize the distance between the means of the two classes and minimizes the \\nvariation within each class.  \\nIn other words, we can say that the new axis will  increase the separation between the \\ndata points of the two classes and plot them onto the new axis.  \\n \\n \\nExample: Iris Flower Classification  \\n \\n \\nSuppose we have a dataset of iris flowers with four features: sepal length, sepal width, petal \\nlength, and petal width. We want to classify these flowers into three species: Setosa, \\nVersicolor, and Virginica.  \\nSteps:  \\n1. Data Preparation:  Let’s say we have 150 iris samples with four features each, \\nand the samples are evenly distributed among the three species.  \\n2. Compute Class Statistics:  Calculate the mean and covariance matrix for each \\nfeature in each class. This gives us three mean vectors and three covariance \\nmatrices (one for each class).  \\n3. Compute Between -Class and Within -Class Scatter Matrices:  Calculate the \\nbetween -class scatter matrix by computing the differences between the mean \\nvectors of each class and the overall mean, and then summing these outer \\nproduct s. Calculate the within -class scatter matrix by summing the covariance \\nmatrices of each class, weighted by the number of samples in each class.  \\n4. Compute Eigenvectors and Eigenvalues:  Solve the generalized eigenvalue \\nproblem using the between -class scatter m atrix and the within -class scatter \\nmatrix. This gives us a set of eigenvectors and their corresponding eigenvalues.  \\n5. Select Discriminant Directions:  Sort the eigenvectors by their eigenvalues in \\ndescending order. Let’s say we want to reduce the dimensionality to 2, so we \\nselect the top two eigenvectors.  \\n6. Transform Data:  Project the original iris data onto the two selected eigenvectors. \\nThis gives us a new two -dimensional representation of the data.  \\n7. Classification:  In the reduced -dimensional space,  we can use a classifier (e.g., k -\\nnearest neighbors) to classify the iris flowers into one of the three species based \\non their positions in the reduced space.  \\nLDA aims to find the projection (linear combination of features) that maximizes the \\nseparation be tween the classes while minimizing the variance within each class. This way, the \\nclasses become more distinguishable in the lower -dimensional space.  \\nIn our iris flower example, LDA would find the best linear combination of sepal length, sepal \\nwidth, petal length, and petal width that maximizes the separability between the Setosa, \\nVersicolor, and Virginica species. The reduced -dimensional space could potentially help in \\nbetter classifying new iris samples . Pros:  \\n1. Dimensionality Reduction with Class Separation : LDA aims to maximize the \\nseparation between classes while reducing the dimensionality of the data. It’s \\nparticularly effective when there’s a clear distinction between classes, and it can \\nhelp improve the efficiency and performance of classification algo rithms.  \\n2. Utilizes Class Information:  LDA takes advantage of class labels during its \\ncomputation, which can lead to better separation of classes compared to \\nunsupervised techniques like Principal Component Analysis (PCA).  \\n3. Works Well for Small Sample Sizes : LDA can handle situations where the \\nnumber of samples is small compared to the number of features. This makes it \\nsuitable for cases where collecting a large amount of training data is challenging.  \\n4. Interpretable Results:  The reduced -dimensional representatio n obtained \\nthrough LDA can often be more interpretable than the original feature space. \\nThis can aid in understanding the important factors driving the classification.  \\n5. Data Visualization : The reduced -dimensional space generated by LDA can be \\nvisualized, ma king it easier to observe the separation between classes and the \\ndistribution of data points.  \\n6. Robust to Outliers : LDA is less sensitive to outliers compared to other methods \\nlike k -nearest neighbors. This is due to its reliance on class means and variances  \\nrather than individual data points.  \\nCons:  \\n1. Sensitive to Class Distribution : LDA assumes that the classes have approximately \\nequal covariance matrices and follow a Gaussian distribution. If these assumptions are not met, the performance of LDA can degrade. In cases where \\nthe assumptions don’t hold, techniques like Quadratic Discriminant Analysis \\n(QDA) or non -parametric methods might be more appropriate.  \\n2. Prone to Overfitting : When the number of features is much larger than the \\nnumber of samples, LDA can be pr one to overfitting. Regularization techniques \\nor dimensionality reduction methods may be needed to address this issue.  \\n3. Doesn’t Handle Nonlinear Relationships:  LDA assumes linear relationships \\nbetween features and classes. If the relationships are nonlinear , LDA might not \\ncapture the underlying patterns accurately.  \\n4. Requires Well -Defined Classes:  LDA is a supervised technique and relies on class \\nlabels for training. If class labels are ambiguous or if the classes are not well -\\ndefined, LDA might not perform op timally.  \\n5. Doesn’t Incorporate Feature Interaction:  LDA considers each feature \\nindependently and doesn’t account for interactions between features. In some \\ncases, interactions might be important for accurate classification.  \\n6. May Not Capture Complex Patterns:  LDA’s linear nature might not capture \\ncomplex decision boundaries that nonlinear techniques like support vector \\nmachines or neural networks can handle.  \\nt-SNE in Machine Learning  \\nHigh -dimensional data can be shown using the non -linear dimensionality reducti on method \\nknown as  t-SNE (t -Distributed Stochastic Neighbor Embedding ). The technique was \\nproposed by  Laurens van der Maaten and Geoffrey Hinton  in 2008  as a new approach for \\nreducing the dimensionality of data that preserves local similarities while compr essing the \\ndata into a lower -dimensional space.  \\nt-SNE is a powerful tool for visualizing complex data, allowing machine learning practitioners \\nto gain insights into the structure of high -dimensional datasets that may be difficult to \\ndiscern using other visualization techniques .  Understanding Dimensionality Reduction  \\nIt is possible to minimize the number of features in a dataset while keeping its key qualities \\nby using the approach of dimensionality reduction. In other words, it aims to simplify \\ncomplex data by reducing the number of variables that are used to describe it.  \\nThe need for dimensionality reduction arises from the fact that many real -world datasets \\ncan contain thousands or even millions of features. These datasets can be challenging to \\nwork wi th, as the sheer number of features can lead to problems with computational \\ncomplexity, model overfitting, and difficulty in interpreting the results.  \\nThere are two main types of dimensionality reduction techniques:  linear and non -linear. \\nLinear techniques , such as  Principal Component Analysis  (PCA), are based on linear algebra \\nand assume that the underlying structure of the data is linear.  Non -linear techniques , on the \\nother hand, are designed to capture more complex, non -linear relationships between the \\nfeatures of the data.  \\nt-SNE is a non -linear technique  that has been shown to be effective at capturing complex data \\nrelationships, making it a powerful tool for machine learning practitioners working with high -\\ndimensional data.  \\nHow t -SNE works?  \\nProbability Distribution  \\nLet’s start with  SNE part of t -SNE. I’m far better with explaining things visually so this is going \\nto be our dataset:  \\nIt has 3 different classes and you can \\neasily distinguish them from each other. The first part of the algorithm is to create \\na probability distribution  that represents similarities between neighbors. What is \\n“similarity ”? Original paper  states “ similarity of datapoint  xⱼ to datapoint  xᵢ is the \\nconditional probability  p_{j|i} , that  xᵢ would pick  xⱼ as its neighbor  “. \\n \\nWe’ve picked one of the points from the dataset. Now we have to pick another point and \\ncalculate Euclidean Distance between them |xᵢ — xⱼ| \\n \\nThe next part of t he original paper states that it has to be  proportional to probability density \\nunder a Gaussian centered at  xᵢ. So we have to generate Gaussian distribution with mean at \\nxᵢ, and place our distance on the X -axis.  \\n \\nRight now you might wonder about  σ² (variance) and that’s a good thing. But let’s just ignore \\nit for now and assume I’ve already decided what it should be. After calculating the first point \\nwe have to do the same thing for every single point out there.  \\n \\nYou might think, we’re already done with this part. But that’s just the beginning.  \\n \\nHow t -SNE Works : \\nSure, here\\'s a simplified explanation of the steps involved in t -SNE: \\n1. Calculate  Pairwise  Similarities : \\n\\uf0b7 Measure how similar each pair of data points is in the high -dimensional \\nspace.  \\n\\uf0b7 Use a Gaussian distribution to compute the similarity.  \\n2. Symmetrize  Similarities : \\n\\uf0b7 Combine the similarities so they\\'re symmetric (bidirectional).  \\n3. Initialize  Embeddings : \\n\\uf0b7 Randomly position each data point in the lower -dimensional space \\n(e.g., 2D or 3D).  \\n4. Compute  Simil arities  in Lower -Dimensional  Space : \\n\\uf0b7 Measure how similar the embedded points are in the lower -\\ndimensional space.  \\n\\uf0b7 Use a Student\\'s t -distribution to compute the similarity.  \\n5. Compute  Gradient : \\n\\uf0b7 Calculate the gradient (direction and magnitude of change) based on \\nthe difference between the original and embedded similarities.  \\n6. Update  Embeddings : \\n\\uf0b7 Adjust the positions of the embedded points to minimize the difference \\nbetween the original and embedded similarities.  \\n\\uf0b7 Use gradient descent to iteratively optimize the embedd ings. \\n7. Repeat : \\n\\uf0b7 Iteratively perform steps 4 -6 until the embeddings stabilize or for a \\nfixed number of iterations.  \\n8. Visualize : \\n\\uf0b7 Plot the embedded points in the lower -dimensional space (e.g., 2D or \\n3D) to visualize the structure of the high -dimensional data.  \\n \\nApplication of t -SNE: \\nImage and Video Processing:  t-SNE can be used to analyze and visualize large sets of images \\nand videos. By reducing the dimensionality of the image or video features, t -SNE can help to \\ncluster similar images and identify patterns in l arge data sets. This makes it a useful tool for \\ncategorizing, segmenting, and retrieving images and videos.  \\nNatural Language Processing:  Natural language processing software frequently makes use of \\nt-SNE. It may be used to illustrate the semantic connectio ns between words in a sizable collection of textual information. By reducing the dimensionality of word embeddings, t -SNE \\ncan help to cluster words that have similar meanings, making it easier to identify patterns in \\nthe data.  \\nBiological Data Analysis:  t-SNE has many applications in the field of biology, particularly in \\nthe analysis of high -dimensional gene expression data. By reducing the dimensionality of gene \\nexpression data, t -SNE can help to identify patterns in the data and cluster genes that have \\nsimilar expression profiles. This can lead to a better understanding of the biological processes \\nthat underlie disease and other complex phenotypes.  \\nAnomaly Detection:  With huge data sets, abnormalities can be found using t -SNE. By \\nvisualizing the data in a l ow-dimensional space, t -SNE can help to identify clusters of data \\npoints that are different from the rest of the data. This can be used to identify potential fraud \\nor other anomalies in financial data or to identify outliers in other types of data sets.  \\nRecommender Systems:  t-SNE can also be used in recommender systems to help identify \\nsimilar items based on their features. By reducing the dimensionality of the item features, t -\\nSNE can help to cluster items that are similar to one another, making it easie r to recommend \\nsimilar items to users based on their preferences.  \\nSocial Network Analysis:  t-SNE can be used to visualize the social networks of large groups of \\npeople. By reducing the dimensionality of social network features, t -SNE can help to identify \\nclusters of people that are connected to one another, making it easier to identify influential \\npeople or groups within the network.  \\nInformation value and Weight of evidence   \\nInformation Value  \\nIV (Information Value) and WOE are closely related. IV is a data exploration technique that \\nhelps determine which variable in a data set has predictive power or influence on the value \\nof a specified dependent variable (0 or 1).  \\nIV is a numerical value that quantifies the overall predictive strength of an independent \\nvariable X in capturing the binary dependent variable Y and is defined mathematically as the \\nsum of the absolute values for WOE across all groups.   \\nIV is helpful for reducing the number of variables used for building a Logistic Regression \\nmodel, especially w hen there are many potential variables. IV analyzes each individual \\nindependent variable in turn without considering other predictor variables. Based on the IV \\nvalues of the variable, we use the below logic to understand its predictive power:  \\n \\nThe Weight o f Evidence (WOE) tells the predictive power of an independent variable in \\nrelation to the dependent variable. Since it evolved from credit scoring world, it is \\ngenerally described as a measure of the separation of good and bad customers.  \"Bad  \\nCustomers\"  refers to the customers who defaulted on a loan. and  \"Good  \\nCustomers\"  refers to the customers who paid back loan.  \\n \\nDistribution  of Goods  - % of Good Customers in a particular group  \\nDistribution  of Bads  - % of Bad Customers in a particular group  \\nln - Natural  Log \\nHow to calculate Weight of Evidence?  \\nFollow the steps below to calculate Weight of Evidence  \\n1. For a continuous variable, split data into 10 parts (or lesser depending \\non the distribution).  \\n2. Calculate the number of events and non -events in each group (bin ) \\n3. Calculate the % of events and % of non -events in each group.  \\n4. Calculate WOE by taking natural log of division of % of non -events and \\n% of events  \\n \\n \\n \\nBenefits of WOE and IV  \\n1. WOE transformations can be used to build linear relationships with log odds which is \\nnot easy otherwise  \\n2. WOE transformation helps us to bin all missing values separately thus treating missing \\nvalues  \\n3. Presence of outliers can greatly affect the predictions. Since WOE groups the values to \\na specific category, raw values can be replaced with  WOE scores  \\n4. IV helps in increasing the prediction power of a model by helping us to select the \\nvariables based on its predictive strength.  \\n \\n \\n \\n \\n \\nUNIT-3 \\nCLASSIFICATION:  \\nWhat is Classification, General Approach to Classification, Multi -class \\nclassification, multi -label classification, Binary Classification, Logistic \\nRegression, Decision Trees,  k-Nearest Neighbo ur Algorithm, Naive Bayesian \\nClassifier and SVM classifier  \\nWhat is Classification  \\nClassification is a supervised machine learning method where the mode l tries \\nto predict the correct label of a given input data. In classification, the model is \\nfully trained using the training data, and then it is evaluated on test data \\nbefore being used to perform prediction on new unseen data.  \\nFor instance, an algorithm can learn to predict whether a given email is spam \\nor ham (no spam), as illustrated below.  \\n  \\n \\n \\n \\nBefore diving into the classification concept, we will first understand the \\ndifference between the two types of learners in classification: lazy and eager \\nlearners. Then we will clarify the misconception between classification and \\nregression.   \\nLazy Learners Vs. Eager Learners  \\nThere are two types of learners in machine learning classification: lazy and \\neager learners.   \\nEager learners  are machine learning algorithms that first build a model from \\nthe training dataset before making any prediction on future datasets. They \\nspend more time during the training process because of their eagerness to \\nhave a better generalization during the training from learning the  weights, but \\nthey require less time to make predictions.   \\nMost machine learning algorithms are eager learners, and below are some \\nexamples:   \\n\\uf0b7 Logistic Regression.   \\n\\uf0b7 Support Vector Machine.   \\n\\uf0b7 Decision Trees.   \\n\\uf0b7 Artificial Neural Networks.   \\nLazy learners or instance -based learners , on the other hand, do not create any \\nmodel immediately from the training data, and this is where the lazy aspect \\ncomes from. They just memorize the training data, and each time there is a \\nneed to make a prediction, they search for the nearest neighbor from the \\nwhole training data, which makes them very slow during prediction. Some \\nexamples of this kind are:   \\n\\uf0b7 K-Nearest Neighbor.   \\n\\uf0b7 Case -based reasoning.   \\nHowever, some algorithms, such as  BallTrees  and KDTrees , can be used to \\nimprove the prediction latency.   \\n \\nFor types and examples refer:  \\nhttps://www.datacamp.com/blog/classification -machine -learning  \\nGeneral Approach to Classification : Classification is a fundamental task in machine learning where the goal is to \\npredict the categorical class labels of new instances based on past \\nobservations. Here\\'s a general approach to classification in machine learning:  \\n \\nDefine the Problem:  Clearly define the problem you\\'re trying to solve. \\nUnderstand the nature of the classes you want to predict and the available \\ndata.  \\n \\nData Collection and Preprocessing:  \\n \\nCollect relevant data for training your model. Ensure that your dataset is \\nlabeled, meaning each data point has a corresponding class label.  \\n \\nPreprocess the data:  \\nHandle missing values: Impute missing values or remove rows/columns with \\nmiss ing data.  \\n \\nEncode categorical variables: Convert categorical variables into numerical \\nrepresentations using techniques like one -hot encoding or label encoding.  \\n \\nFeature scaling:  Scale numerical features to a similar range to prevent certain \\nfeatures from d ominating the model.  \\n \\nFeature selection:  Select relevant features that contribute most to the \\nclassification task.  \\n \\nData Splitting:  Split the dataset into training and testing sets. The training set is \\nused to train the model, while the testing set is used  to evaluate its \\nperformance. Optionally, you can also have a validation set for hyperparameter \\ntuning if you\\'re using techniques like cross -validation.  \\n \\nChoose a Model:  Select an appropriate classification algorithm based on your \\nproblem requirements and the nature of the data. Common algorithms \\ninclude:  \\n \\nLogistic Regression  \\nDecision Trees  \\nRandom Forests  \\nSupport Vector Machines (SVM)  \\nk-Nearest Neighbors (k -NN) Neural Net works  \\nNaive Bayes  \\n \\nModel Training:  Train the chosen model on the training data. During training, \\nthe model learns the patterns and relationships between features and class \\nlabels in the data.  \\n \\nModel Evaluation:  Evaluate the trained model using the testing dataset. \\nCommon evaluation metrics for classification tasks include accuracy, precision, \\nrecall, F1 -score, and confusion matrix. Choose metrics that are appropriate for \\nyour problem, considering factors like class imbalance or the cost of \\nmisclassification . \\n \\nHyperparameter Tuning: Fine -tune the model\\'s hyperparameters to improve \\nits performance. This can be done using techniques like grid search, random \\nsearch, or Bayesian optimization.  \\n \\nModel Deployment: Once satisfied with the model\\'s performance, deploy it for \\nmaking predictions on new, unseen data. This could involve integrating the \\nmodel into a software application, web service, or production pipeline.  \\n \\nMonitoring and Maintenance:  Continuously monitor the deployed model\\'s \\nperformance in the production e nvironment. Retrain the model periodically \\nwith new data to ensure its relevance and accuracy over time.  \\n \\nIterative Improvement:  Iterate over the entire process, refining and improving \\nthe model as needed based on feedback and new data.  \\n \\nBy following these  steps, you can develop effective classification models for a \\nwide range of machine learning problems  \\n \\nMulti -class classification, multi -label classification, Binary Classification   \\n\\uf0b7  \\n\\uf0b7 Binary classification is  a machine learning algorithm that predicts a bin ary \\noutcome, such as positive or negative, from a set of training data.  The model \\nuses features (variables) and labels (categories) to identify patterns and \\nmake predictions.  The model is then evaluated based on its ability to \\naccurately predict the correc t labels for new data.   \\n\\uf0b7 In a binary classification task, the goal is to classify the input data into two \\nmutually exclusive categories.  For example, you might want to detect \\nwhether a given image is a truck or a boat.  The training data in such a situation is labeled in a binary f ormat: true and false;  positive and \\nnegative;  O and 1;  spam and not spam, etc..   \\n\\uf0b7 Binary classification is used in a wide range of applications, such as:  spam \\nemail detection, medical diagnosis, sentiment analysis, and fraud detection.   \\n\\uf0b7 Some algorithms that  can be used for binary classification include:  Logistic \\nRegression, Support Vector Machines, K -Nearest Neighbors, and Decision \\nTrees.   \\n\\uf0b7 The raw data might represent the classes by strings like \"Yes\" and \"No\", or \\n\"Dog\" and \"Cat\".  Before using this data, you \\'ll assign a class label: one class \\nwill be 0 and the other will be 1.  Assigning numeric labels puts the data in a \\nform a neural network can use.   \\n \\nMulticlass classification is a machine learning classification task that consists of more than \\ntwo classes,  or outputs.  \\nFor example, using a model to identify animal types in images from an encyclopedia is a \\nmulticlass classification example because there  are many different animal classifications that \\neach image can be classified as. Multiclass classification also requires that a sample  only \\nhave one class (ie. an elephant is only an elephant; it is not also a lemur).  \\nOutside of regression, multiclass clas sification is probably the most common machine \\nlearning task. In classification, we are presented with a number of training examples divided \\ninto K separate classes, and we build a  machine l earning model  to predict which of those \\nclasses some previously unseen data belongs to (ie. the animal types from the previous \\nexample). In seeing the training dataset, the model learns patterns specific to each class and \\nuses those patterns to predict the  membership of future data.  \\nFor instance, images of cats may all follow a pattern of pointed ears and whiskers, helping the \\nmodel to identify future images of cats as compared to other animals without whiskers or \\npointed ears.  \\nWhether you’re new to  machine learning , or an experienced  data scientist , the way you use \\nand train your  dataset  is the key to extracting actionable in sights.  \\nMost of the binary classification algorithms can be also used for multi -class \\nclassification. These algorithms include but are not limited to:  \\n\\uf0b7 Random Forest  \\n\\uf0b7 Naive Bayes   \\n\\uf0b7 K-Nearest Neighbors   \\n\\uf0b7 Gradient Boosting   \\n\\uf0b7 SVM  \\n\\uf0b7 Logistic Regression.  But wait! Didn’t you say that SVM and Logistic Regression do not support multi -class \\nclassification by default?   \\n→ That’s correct. However, we can apply binary transformation approaches such as one -\\nversus -one and one -versus -all to adapt native binary classification algorithms for multi -\\nclass classification tasks.  \\n \\nOne-versus -one : this strategy trains as many classifiers as there are pairs of labels. If \\nwe have a 3 -class classification, we will have three pairs of labels, thus three classifiers, \\nas shown below.   \\n \\nIn general, for N labels, we will have Nx(N -1)/2 classifiers. Each classifier is trained on a \\nsingle binary dataset, and the final class is predicted by a majority vote between all the \\nclassifiers. One -vs-one approach works best for SVM and other kernel -based \\nalgorithms.   \\nOne-versus -rest : at this stage, we start by considering each label as an independent \\nlabel and consider the rest combined as only one label. With 3 -classes, we will have \\nthree classifiers.   \\nIn general, for N labels, we will have  N binary c lassifiers.  \\n \\nWhat  is Multi -label  Classification?  \\nMulti -label  classification  is a machine  learning  paradigm  where  instances  can be \\nassociated  with multiple  labels  simultaneously.  Unlike  traditional  classification  \\ntasks,  where  an instance  is assigned  a single  exclusive  label,  multi -label  \\nclassification  recognizes  the possibility  for instances  to exhibit  characteristics  \\nthat span  across  various  categories.  The goal is to develop  models  capable  of \\naccurately  predicting  and assigning  a set of relevant  label s to each instance,  \\nreflecting  the complex  relationships  and diversity  inherent  in real-world  datasets.  \\nThis approach  acknowledges  the overlapping  nature  of labels,  providing  a more  \\nrealistic  representation  of the multifaceted  attributes  present  in the data. \\nMulti -label  classification  is a machine  learning  task where  instances  can be \\nassociated  with multiple  labels  simultaneously.  This differs  from  multiclass  \\nclassification,  where  each instance  is assigned  to one and only one class.  In multi -\\nlabel  scenarios , an instance  may exhibit  characteristics  that correspond  to several  \\ndifferent  categories,  making  the task more  intricate  and reflecting  the complexity  \\noften  found  in real-world  data.  \\nMulti -label  classification  is highly  applicable  in diverse  scenarios  where instances  \\ncan possess  multiple  attributes  or labels.  Examples  include:  \\n\\uf0b7 Document  Tagging:  Assigning  multiple  tags or topics  to a document,  \\nsuch as labeling  an article  as both “technology”  and “business.”  \\n\\uf0b7 Image  Classification  with  Multiple  Labels : Identif ying and labeling  \\nmultiple  objects  or features  within  an image,  like recognizing  both \\n“cat”  and “outdoor”  in a photograph.  \\nModel  Training  Techniques:  \\nTraining  models  for multi -label  classification  involves  specific  techniques  to \\naccommodate  the simultaneous  assignment  of multiple  labels  to instances:  \\n\\uf0b7 Sigmoid  Activation:  In the output  layer  of the neural  network , sigmoid  \\nactivation  is often  used.  Unlike  softmax  in multiclass  \\nscenarios,  sigmoid  independently  activates  each  output  node,  producing  \\na value  between  0 and 1, representing  the likelihood  of the \\ncorresponding  label  being  present.  \\n\\uf0b7 Binary  Cross -Entropy  Loss:  This loss function  is employed  during  \\ntraining  to measure  the dissimilarity  between  the predicted  probabilities  \\nand the actual  presence  or absence  of each  label.  It guides  the model  to \\nminimize  errors  in its multi -label  predictio ns. \\n \\nCART  Algorithm  \\nClassification  and Regression  Trees  (CART)  is a decision  tree algorithm  that is \\nused for both classification  and regression  tasks.  It is a supervised  learning  \\nalgorithm  that learns  from  labelled  data to predict  unseen  data.  \\n\\uf0b7 Tree  structure:  CART  builds  a tree-like structure  consisting  of nodes  \\nand branches.  The nodes  represent  different  decision  points,  and the \\nbranches  represent  the possible  outcomes  of those  decisions.  The leaf \\nnodes  in the tree contain  a predicted  class  label  or value  for the target  \\nvariable.  \\n\\uf0b7 Splitting  criteria:  CART  uses a greedy  approach  to split the data at \\neach node.  It evaluates  all possible  splits  and selects  the one that best \\nreduces  the impurity  of the resulting  subsets.  For classification  tasks,  \\nCART  uses Gini impurity  as the splitting  criterion.  The lower  the Gini \\nimpurity,  the more  pure the subset  is. For regression  tasks,  CART  uses \\nresidual  reduction  as the splitting  criterion.  The lower  the residual  \\nreduction,  the better  the fit of the model  to the data.  \\n\\uf0b7 Pruning:  To prevent  overfitting  of the data,  pruning  is a technique  used  \\nto remove  the nodes  that contribute  little  to the model  accuracy.  Cost \\ncomplexity  pruning  and information  gain pruning  are two popular  \\npruning  techniques.  Cost complexity  pruni ng involves  calculating  the \\ncost of each  node  and removing  nodes  that have  a negative  cost.  \\nInformation  gain pruning  involves  calculating  the information  gain of \\neach node  and removing  nodes  that have  a low information  gain.  \\nHow  does CART  algorithm  works?  \\nThe CART  algorithm  works  via the following  process:  \\n\\uf0b7 The best-split point  of each input  is obtained.   \\n\\uf0b7 Based  on the best-split points  of each input  in Step 1, the new “best”  \\nsplit point  is identified.   \\n\\uf0b7 Split  the chosen  input  according  to the “best”  split point.  \\n\\uf0b7 Continue  splitting  until a stopping  rule is satisfied  or no further  \\ndesirable  splitting  is available.   \\nCART  algorithm  uses Gini Impurity  to split the dataset  into a decision  tree .It \\ndoes that by searching  for the best homogeneity  for the sub nodes,  with the help \\nof the Gini index  criterion.  \\n \\n \\nRefer:  \\nhttps://www.knowledgehut.com/blog/data -science/types -of-classification -in-\\nml#gradi ent-boosting%C2%A0  \\nor \\nhttps://www.datacamp.com/blog/classification -machine -learning  \\n \\nLogistic  regression:  \\no Logistic regression is one of the most popular Machine Learning algorithms, \\nwhich comes under the Supervised Learning technique. It is used for predicting \\nthe categorical dependent variable using a given set of independent variables.  \\no Logistic regression predicts the output of a categorical dependent variable. \\nTherefore  the outcome must be a categorical or discrete value. It can be either \\nYes or No, 0 or 1, true or False, etc. but instead of giving the exact value as 0 \\nand 1,  it gives the probabilistic values which lie between 0 and 1 . \\no Logistic Regression is much similar  to the Linear Regression except that how \\nthey are used. Linear Regression is used for solving Regression problems, \\nwhereas  Logistic regression is used for solving the classification problems . \\no In Logistic regression, instead of fitting a regression line, w e fit an \"S\" shaped \\nlogistic function, which predicts two maximum values (0 or 1).  \\no The curve from the logistic function indicates the likelihood of something such \\nas whether the cells are cancerous or not, a mouse is obese or not based on its \\nweight, etc.  \\no Logistic Regression is a significant machine learning algorithm because it has \\nthe ability to provide probabilities and classify new data using continuous and \\ndiscrete datasets.  \\no Logistic Regression can be used to classify the observations using different \\ntypes of data and can easily determine the most effective variables used for the \\nclassification. The below image is showing the logistic function:  \\n \\nTypes  of Logistic  Regression  with  Examples  \\nLogistic  regression  is classified  into binary,  multinomial,  and ordinal.  Each  type  \\ndiffers  from  the other  in execution  and theory.  Let’s  understand  each  type  in \\ndetail.  \\n1. Binary  logistic  regression  \\nBinary  logistic  regression  predicts  the relationship  between  the independent  \\nand binary  dependent  variables.  Some  example s of the output  of this \\nregression  type  may  be, success/failure,  0/1, or true/false.  \\nExamples : \\n1. Deciding  on whether  or not to offer  a loan  to a bank  customer:  \\nOutcome  = yes or no. \\n2. Evaluating  the risk of cancer:  Outcome  = high  or low. \\n3. Predicting  a team ’s win in a football  match:  Outcome  = yes or no. \\n2. Multinomial  logistic  regression  \\nA categorical  dependent  variable  has two or more  discrete  outcomes  in a \\nmultinomial  regression  type.  This implies  that this regression  type  has more  \\nthan  two possible  outcomes.  \\nExamples : \\n1. Let’s say you want  to predict  the most  popular  transportation  type  \\nfor 2040.  Here,  transport  type  equates  to the dependent  variable,  \\nand the possible  outcomes  can be electric  cars,  electric  trains,  \\nelectric  buses,  and electric  bikes.  \\n2. Predicting  whether  a student  will join a college,  vocational/trade  \\nschool,  or corporate  industry.  \\n3. Estimating  the type  of food  consumed  by pets,  the outcome  may  be \\nwet food,  dry food,  or junk  food.  \\n3. Ordinal  logistic  regression  \\nOrdinal  logistic  regression  applies  when  the dependent  variable  is in an \\nordered  state  (i.e.,  ordinal).  The dependent  variable  (y) specifies  an order  with  \\ntwo or more  categories  or levels.  \\nExamples : Dependent  variables  represent,  \\n1. Formal  shirt  size:  Outcomes  = XS/S/M/L/XL  \\n2. Survey  answers:  Outcomes  = Agree/Disagree/Unsure  \\n3. Scores  on a math  test:  Outcomes  = Poor/Average/Good  \\n \\nDecision Trees  Decision Tree Classification Algorithm  \\no Decision Tree is a  Supervised learning technique  that can be used for both \\nclassification and Regression problems, but mostly  it is preferred for solving \\nClassification problems. It is a tree -structured classifier, where  internal nodes \\nrepresent the features of a dataset, branches represent the decision \\nrules  and each leaf node represents the outcome.  \\no In a Decision tree, there a re two nodes, which are the  Decision Node  and Leaf \\nNode.  Decision nodes are used to make any decision and have multiple branches, \\nwhereas Leaf nodes are the output of those decisions and do not contain any further \\nbranches.  \\no The decisions or the test are pe rformed on the basis of features of the given dataset.  \\no It is a graphical representation for getting all the possible solutions to a \\nproblem/decision based on given conditions.  \\no It is called a decision tree because, similar to a tree, it starts with the root  node, which \\nexpands on further branches and constructs a tree -like structure.  \\no In order to build a tree, we use the  CART algorithm,  which stands for  Classification \\nand Regression Tree algorithm.  \\no A decision tree simply asks a question, and based on the answ er (Yes/No), it further \\nsplit the tree into subtrees.  \\no Below diagram explains the general structure of a decision tree:  Note: A decision tree can contain categorical data (YES/NO) as well as numeric data.  \\n \\no Step -1: Begin the tree with the root node, says S,  which contains the complete \\ndataset.  \\no Step -2: Find the best attribute in the dataset using  Attribute Selection \\nMeasure (ASM).  \\no Step -3: Divide the S into subsets that contains possible values for the best \\nattributes.  \\no Step -4: Generate the decision tree node, which contains the best attribute.  \\no Step -5: Recursively make new decision trees using the subsets of the dataset \\ncreated in step -3. Continue this process until a stage is reached where you \\ncannot further classify the nodes and called the final node as a le af node.  \\n \\nExample:  Suppose there is a candidate who has a job offer and wants to decide \\nwhether he should accept the offer or Not. So, to solve this problem, the decision tree \\nstarts with the root node (Salary attribute by ASM). The root node splits furthe r into \\nthe next decision node (distance from the office) and one leaf node based on the \\ncorresponding labels. The next decision node further gets split into one decision node \\n(Cab facility) and one leaf node. Finally, the decision node splits into two leaf  nodes \\n(Accepted offers and Declined offer). Consider the below diagram:  \\n \\nhttps://www.javatpoint.com/machine -learning -decision -tree-classification -algorithm  \\n \\nSVM classifier  \\nSupport Vector Machine Algorithm  \\nSupport Vector Machine or SVM is one of the most popular Supervised Learning \\nalgorithms, which is used for Classification as well as Regression problems. However, \\nprimarily, it is used for Classification problems in Machine Learning.  \\nThe goal of the SVM algorithm is to create the best line or decision boundary that can \\nsegregate n -dimensional space into classes so that we can easily put the new data \\npoint in the correct category in the future. This best de cision boundary is called a \\nhyperplane.  \\nSVM chooses the extreme points/vectors that help in creating the hyperplane. These \\nextreme cases are called as support vectors, and hence algorithm is termed as Support \\nVector Machine. Consider the below diagram in w hich there are two different \\ncategories that are classified using a decision boundary or hyperplane:  \\n \\nTypes of SVM  \\nSVM can be of two types:  \\no Linear SVM:  Linear SVM is used for linearly separable data, which means if a \\ndataset can be classified into two classes by using a single straight line, then \\nsuch data is termed as linearly separable data, and classifier is used called as \\nLinear SVM classifier.  \\no Non-linear SVM:  Non-Linear SVM is used for non -linearly separated data, \\nwhich means if a dataset cannot be  classified by using a straight line, then such \\ndata is termed as non -linear data and classifier used is called as Non -linear SVM \\nclassifier.  \\nHyperplane and Support Vectors in the SVM algorithm:  \\nHyperplane:  There can be multiple lines/decision boundaries to segregate the classes \\nin n-dimensional space, but we need to find out the best decision boundary that helps \\nto classify the data points. This best boundary is known as the hyperplane of SVM.  \\nThe dimensions of the hyperplane depend on the features presen t in the dataset, \\nwhich means if there are 2 features (as shown in image), then hyperplane will be a \\nstraight line. And if there are 3 features, then hyperplane will be a 2 -dimension plane.  \\nWe always create a hyperplane that has a maximum margin, which mea ns the \\nmaximum distance between the data points.  \\nSupport Vectors:  \\nThe data points or vectors that are the closest to the hyperplane and which affect the \\nposition of the hyperplane are termed as Support Vector. Since these vectors support \\nthe hyperplane, he nce called a Support vector.  \\nHow does SVM works?  \\nLinear SVM:  \\nThe working of the SVM algorithm can be understood by using an example. Suppose \\nwe have a dataset that has two tags (green and blue), and the dataset has two features \\nx1 and x2. We want a classif ier that can classify the pair(x1, x2) of coordinates in either \\ngreen or blue. Consider the below image:  \\n \\nSo as it is 2 -d space so by just using a straight line, we can easily separate these two \\nclasses. But there can be multiple lines that can separate these classes. Consider the \\nbelow image:  \\n \\nHence, the SVM algorithm helps to find the best line or decision boundary; this best \\nboundary or region is called as a  hyperplane . SVM algorithm finds the closest point \\nof the lines from both the classes. These po ints are called support vectors. The distance \\nbetween the vectors and the hyperplane is called as  margin . And the goal of SVM is \\nto maximize this margin. The  hyperplane  with maximum margin is called the  optimal \\nhyperplane . \\n \\n \\n \\n \\nhttps://www.javatpoint.com/machine -learning -support -vector -machine -algorithm  \\n \\nNaive Bayesian Classifier  \\no Naïve Bayes algorithm is a supervised learning algorithm, wh ich is based on  Bayes \\ntheorem  and used for solving classification problems.  \\no It is mainly used in  text classification  that includes a high -dimensional training dataset.  \\no Naïve Bayes Classifier is one of the simple and most effective Classification algorithms  \\nwhich helps in building the fast machine learning models that can make quick \\npredictions.  \\no It is a probabilistic classifier, which means it predicts on the basis of the \\nprobability of an object . \\no Some popular examples of Naïve Bayes Algorithm are  spam filtration, Sentimental \\nanalysis, and classifying articles . \\nWhy is it called Naïve Bayes?  \\nThe Naïve Bayes algorithm is comprised of two words Naïve and Bayes, Which can be \\ndescribed as:  \\no Naïve : It is called Naïve because it assumes that the occurrence of a certain feature is \\nindependent of the occurrence of other features. Such as if the fruit is identified on the \\nbases of color, shape, and taste, then red, spherical, and sweet fruit is recogni zed as an \\napple. Hence each feature individually contributes to identify that it is an apple without \\ndepending on each other.  \\no Bayes : It is called Bayes because it depends on the principle of  Bayes\\' Theorem . \\nBayes\\' Theorem:  \\no Bayes\\' theorem is also known as  Bayes\\' Rule  or Bayes\\' law , which is used to determine \\nthe probability of a hypothesis with prior knowledge. It depends on the conditional \\nprobability.  \\no The formula  for Bayes\\' theorem is given as:  \\n \\nWhere,  \\nP(A|B) is Posterior probability : Probability of hypothesis A on the observed event B.  \\nP(B|A) is Likelihood probability : Probability of the evidence given that the \\nprobability of a hypothesis is true.  \\nP(A) is Prior Probability : Probability of hypothesis before observing the evidence.  \\nP(B) is Marginal Probability : Probability of Evidence.  \\nWorking of Naïve Bayes\\' Classifier:  \\nWorking of Naïve Bayes\\' Classifier can be understood with the help of the below example:  \\nOutlook  Play  \\n0 Rainy  Yes \\n1 Sunny  Yes \\n2 Overcast  Yes \\n3 Overcast  Yes \\n4 Sunny  No \\n5 Rainy  Yes \\n6 Sunny  Yes \\n7 Overcast  Yes \\n8 Rainy  No \\n9 Sunny  No \\n10 Sunny  Yes \\n11 Rainy  No \\n12 Overcast  Yes Suppose we have a dataset of  weather conditions  and corresponding target variable \\n\"Play \". So using this dataset we need to decide that whether we should play or not on a \\nparticular day according to the weather conditions. So to solve this problem, we need to \\nfollow the below steps:  \\n1. Convert the given dataset into frequency tables.  \\n2. Generate Likelihood table by finding the probabilities of given features.  \\n3. Now, use Bayes theorem to calculate the posterior probability.  \\nProblem : If the weather is sunny, then the Player should play or not?  \\nSolution : To solve this, first consider the below dataset:  \\nFrequency table for the Weather Conditions:  \\nWeather  Yes No \\nOvercast  5 0 \\nRainy  2 2 \\nSunny  3 2 \\nTotal  10 5 \\nLikelihood table weather condition:  \\nWeather  No Yes  \\nOvercast  0 5 5/14= 0.35  \\nRainy  2 2 4/14=0.29  \\nSunny  2 3 5/14=0.35  \\nAll 4/14=0.29  10/14=0.71   \\nApplying Bayes\\'theorem:  \\nP(Yes|Sunny)= P(Sunny|Yes)*P(Yes)/P(Sunny)  \\nP(Sunny|Yes)= 3/10= 0.3  13 Overcast  Yes P(Sunny)= 0.35  \\nP(Yes)=0.71  \\nSo P(Yes|Sunny) = 0.3*0.71/0.35=  0.60 \\nP(No|Sunny)= P(Sunny|No)*P(No)/P(Sunny)  \\nP(Sunny|NO )= 2/4=0.5  \\nP(No)= 0.29  \\nP(Sunny)= 0.35  \\nSo P(No|Sunny)= 0.5*0.29/0.35 =  0.41 \\nSo as we can see from the above calculation that  P(Yes|Sunny)>P(No|Sunny)  \\nHence on a Sunny day, Player can play the game  \\n \\nhttps://www.javatpoint.com/machine -learning -naive -bayes -classifier  \\n \\nk-Nearest Neighbour Algorithm  \\no K-Nearest Neighbour is one of the simplest Machine Learning algorithms based \\non Supervised Learning technique.  \\no K-NN algorithm assumes the similarity between the new case/data and \\navailable cases and put the new case into the category that is most similar to \\nthe available categories.  \\no K-NN algorithm stores all the available data and classifies a new data point \\nbased on the similarity. This means when new data appears then it can be easily \\nclassified into a well suite category by using K - NN algorithm.  \\no K-NN algorithm can be used for Regression as well as for Classification but \\nmostly i t is used for the Classification problems.  \\no K-NN is a  non-parametric algorithm , which means it does not make any \\nassumption on underlying data.  \\no It is also called a  lazy learner algorithm  because it does not learn from the \\ntraining set immediately instead it  stores the dataset and at the time of \\nclassification, it performs an action on the dataset.  o KNN algorithm at the training phase just stores the dataset and when it gets \\nnew data, then it classifies that data into a category that is much similar to the \\nnew data.  \\no Example:  Suppose, we have an image of a creature that looks similar to cat and \\ndog, but we want to know either it is a cat or dog. So for this identification, we \\ncan use the KNN algorithm, as it works on a similarity measure. Our KNN model \\nwill find  the similar features of the new data set to the cats and dogs images \\nand based on the most similar features it will put it in either cat or dog category.  \\nHow does K -NN work?  \\nThe K -NN working can be explained on the basis of the below algorithm:  \\no Step -1: Select the number K of the neighbors  \\no Step -2: Calculate the Euclidean distance of  K number of neighbors  \\no Step -3: Take the K nearest neighbors as per the calculated Euclidean distance.  \\no Step -4: Among these k neighbors, count the number of the data points in e ach \\ncategory.  \\no Step -5: Assign the new data points to that category for which the number of \\nthe neighbor is maximum.  \\no Step -6: Our model is ready.  \\nSuppose we have a new data point and we need to put it in the required category. \\nConsider the below image:   \\no Firstly, we will choose the number of neighbors, so we will choose the k=5.  \\no Next, we will calculate the  Euclidean distance  between the data points. The \\nEuclidean distance is the distance between two points, which we have already \\nstudied in geometry. It can  be calculated as:  \\n \\no By calculating the Euclidean distance we got the nearest neighbors, as three \\nnearest neighbors in category A and two nearest neighbors in category B. \\nConsider the below image:  \\n \\no As we can see the 3 nearest neighbors  are from category A, hence this new data \\npoint must belong to category A.  \\n \\n \\nhttps://www.javatpoint.com/k -nearest -neighbor -algorithm -for-machine -learning  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT-3 \\nMODEL METRICS:  ROC Curves, Confusion matrix, Holdout Method, Cross \\nValidation, Bootstrap  \\nROC Curves:  \\nA ROC (which stands for “receiver operating characteristic ”) curve is a graph that shows a \\nclassification model performance at all classification thresholds. It is a probability curve that \\nplots two parameters, the True Positive Rate (TPR) against the False Positive Rate (FPR), at \\ndifferent threshold values and separates a so -called ‘signal ’ from the ‘noise. ’ \\nThe ROC curve plots the T rue Positive Rate against the False Positive Rate at different \\nclassification thresholds. If the user lowers the classification threshold, more items get \\nclassified as positive, which increases both the False Positives and True Positives. You can see \\nsome imagery regarding this here.  \\n \\nReceiver Operating Characteristic (ROC) curves are a fundamental tool in evaluating the \\nperformance of binary classification models in machine learning. They provide a graphical \\nrepresentation of the trade -off between the true  positive rate (sensitivity) and the false \\npositive rate (1 - specificity) across various threshold values.  \\n \\n \\nHere\\'s how ROC curves work and why they\\'re important:  \\n \\nTrue Positive Rate (TPR) or Sensitivity: This measures the proportion of actual positive c ases \\nthat are correctly identified by the model. It\\'s calculated as TP / (TP + FN), where TP is the \\nnumber of true positives and FN is the number of false negatives.  \\n \\nFalse Positive Rate (FPR) or 1 - Specificity:  This measures the proportion of actual nega tive \\ncases that are incorrectly classified as positive by the model. It\\'s calculated as FP / (FP + TN), \\nwhere FP is the number of false positives and TN is the number of true negatives.  \\n \\nThe ROC curve is created by plotting the TPR (sensitivity) against th e FPR (1 - specificity) for \\ndifferent threshold values used by the model to classify instances as positive or negative. \\nEach point on the ROC curve represents a different threshold.  \\n \\nA model with perfect classification accuracy would have an ROC curve that  passes through \\nthe upper -left corner of the plot (TPR = 1, FPR = 0), indicating high sensitivity and low false \\npositive rate. On the other hand, a model with random guessing would have an ROC curve \\nthat follows the diagonal line (y = x), indicating no dis crimination capability.  \\n \\nKey points to consider about ROC curves:  \\n \\nArea Under the Curve (AUC):  This metric quantifies the overall performance of the model. A \\nhigher AUC indicates better discrimination ability. AUC values typically range from 0 to 1, \\nwhere 0.5 indicates random guessing and 1 indicates perfect classification.  \\n \\nModel Comparison:  ROC curves are particularly useful for comparing the performance of \\ndifferent models. The model with a higher AUC generally performs better.  \\n \\nThreshold Selection:  ROC curves help in selecting an appropriate threshold based on the \\nspecific requirements of the problem. A threshold that balances sensitivity and specificity \\ncan be chosen depending on the application\\'s priorities (e.g., minimizing false positives or \\nfalse ne gatives).  \\n \\nImbalanced Classes:  ROC curves are robust to class imbalance because they evaluate model \\nperformance across different threshold values.  \\n \\nIn summary, ROC curves provide a comprehensive way to assess and compare the \\nperformance of binary classification models, offering insights into sensitivity, specificity, and \\nthe trade -offs between them.  \\nConfusion matrix:  \\nClassification Models have multiple categorical outputs. Most error measures will calculate \\nthe total error in our model, but we cann ot find individual instances of errors in our model. \\nThe model might misclassify some categories more than others, but we cannot see this \\nusing a standard accuracy measure.  \\nFurthermore, suppose there is a significant class imbalance in the given data. In t hat case, \\ni.e., a class has more instances of data than the other classes, a model might predict the \\nmajority class for all cases and have a high accuracy score; when it is not predicting the \\nminority classes. This is where confusion matrices are useful.  \\nA confusion matrix presents a table layout of the different outcomes of the prediction and \\nresults of a classification problem and helps visualize its outcomes.  \\nIt plots a table of all the predicted and actual values of a classifier.   \\nHow to Create a 2x2 C onfusion Matrix?  \\nWe can obtain four different combinations from the predicted and actual values of a \\nclassifier:  \\n \\nFigure 2: Confusion Matrix  \\n\\uf0b7 True Positive: The number of times our actual positive values are equal to the \\npredicted positive. You predicted a  positive value, and it is correct.  \\n\\uf0b7 False Positive: The number of times our model wrongly predicts negative values as \\npositives. You predicted a negative value, and it is actually positive.  \\n\\uf0b7 True Negative: The number of times our actual negative values are equal to \\npredicted negative values. You predicted a negative value, and it is actually \\nnegative.  \\n\\uf0b7 False Negative: The number of times our model wrongly predicts negative values \\nas positives. You predicted a negative value, and it is actually positive.  \\nConfusion Matrix Metrics  \\n \\nFigure 3: Confusion Matrix for a classifier  \\nConsider a confusion matrix made for a classifier that classifies people based on whether \\nthey speak English or Spanish.  \\nFrom the above diagram, we can see that:  \\nTrue Positives (TP) = 8 6 \\nTrue Negatives (TN) = 79  \\nFalse Positives (FP) = 12  \\nFalse Negatives (FN) = 10  \\nJust from looking at the matrix, the performance of our model is not very clear. To find how \\naccurate our model is, we use the following metrics:  \\n\\uf0b7 Accuracy: The accuracy is used to find the portion of correctly classified values. It \\ntells us how often our classifier is right. It is the sum of all true values divided by \\ntotal values.  \\n \\nFigure 4: Accuracy  \\nIn this case:  \\nAccuracy = (86 +79) / (86 + 79 + 12 + 10) = 0.8823 = 88.23%  \\n\\uf0b7 Precision: Precision is used to calculate the model\\'s ability to classify positive \\nvalues correctly. It is the true positives divided by the total number of predicted \\npositive values.  \\n \\nFigure 5: Precision  \\nIn this case,  \\nPrecision = 86 / (86 + 12) = 0.8775 = 87.75%  \\n\\uf0b7 Recall: It is used to calculate the model\\'s ability to predict positive values. \"How \\noften does the model predict the correct positive values?\". It is the true positives \\ndivided by the total number of actual positive values.    \\n   \\nFigure 6: Recall                         \\nIn this case,  \\nRecall = 86 / (86 + 10) = 0.8983 = 89.83%  \\n\\uf0b7 F1-Score: It is the harmonic mean of Recall and Precision. It is useful when you \\nneed to take both Precision and Recall into account.  \\n \\nFigure 7: F1 -Score  \\nIn this case,  \\nF1-Scor e = (2* 0.8775 * 0.8983) / (0.8775 + 0.8983) = 0.8877 = 88.77%  \\nScaling a Confusion Matrix  \\nTo scale a confusion matrix, increase the number of rows and columns. All the True Positives \\nwill be along the diagonal. The other values will be False Positives or F alse Negatives.  \\n \\n \\nFigure 12: Scaling down our dataset  \\nNow that we understand what a confusion matrix is and its inner working, let\\'s explore how \\nwe find the accuracy of a model with a hands -on demo on confusion matrix with Python.  \\nHoldout Method : \\nThe hold -out method for training a machine learning model is the process of splitting the \\ndata into different splits and using  one split  for training  the model and  other  splits  for \\nvalidating  and testing  the models. The hold -out method is used for both  model  \\nevaluation  and model  selection.  The following represents the data splits used in hold out \\nmethod.  \\n \\nWhen the entire data is used for training the model using different algorithms, the problem \\nof evaluating the models and selecting the most optimal model rem ains. The primary task is \\nto find out which model out of all models has the  lowest  generalization  error . In other \\nwords, which model makes a better prediction on future or  unseen  datasets  than all other \\nmodels. This is where the need to have some mechanism  arises wherein the model is \\ntrained on one data set, and, validated and tested on another dataset. This is where the \\nhold -out method comes into the picture.  \\nHold -out method for Model Evaluation  \\n \\nThe hold -out method for model evaluation represents the mech anism of splitting the \\ndataset into training and test datasets. The model is trained on the training set and then \\ntested on the testing set to get the most optimal model. This approach is often used when \\nthe data set is small and there is not enough data t o split into three sets (training, validation, \\nand testing). This approach has the advantage of being simple to implement, but it can be \\nsensitive to how the data is divided into two sets. If the split is not random, then the results \\nmay be biased. Overall , the hold out method for model evaluation is a good starting point \\nfor training machine learning models, but it should be used with caution. The following \\nrepresents the hold -out method for model evaluation.  \\nFig 1. Hold -out method  for model  evaluation  \\nIn the above diagram, you may note that the data set is split into two parts. One split is set \\naside or held out for training the model. Another set is set aside or held out for testing or \\nevaluating the model. The split percentage is decided based on the vo lume of the data \\navailable for training purposes. Generally, 70 -30% split is used for splitting the dataset \\nwhere 70% of the dataset is used for training and 30% dataset is used for testing the model.  \\nThis technique is well suited if the goal is to compare  the models based on the model \\naccuracy on the test dataset and select the best model.  However,  there  is always  a \\npossibility  that  trying  to use this technique  can result  in the model  fitting  well  to the test \\ndataset.  In other words, the models are trained  to improve model accuracy on the test \\ndataset assuming that the test dataset represents the population. The test error, thus, \\nbecomes  an optimistically  biased  estimation  of generalization  error . However, that is not \\ndesired. The final model fails to gener alize well to the unseen or future dataset as it is \\ntrained to fit well (or overfit) concerning the test data.  \\nThe following is the process of using the hold -out method for model evaluation:  \\n\\uf0b7 Split the dataset into two parts (preferably based on a 70 -30% split; However, \\nthe percentage split will vary)  \\n\\uf0b7 Train the model on the training dataset; While training the model, some fixed \\nset of hyperparameters is selected.  \\n\\uf0b7 Test or evaluate the model on the held -out test dataset  \\n\\uf0b7 Train the final model on the entire da taset to get a model which can generalize \\nbetter on the unseen or future dataset.  \\nNote that this process is used for model evaluation based on splitting the dataset into \\ntraining and test datasets and using a fixed set of hyperparameters. There is another \\ntechnique of splitting the data into three sets and using these three sets for model selection \\nor hyperparameters tuning. We will look at that technique in the next section . \\nCross Validation  \\nCross -validation is a technique for validating the model efficien cy by training it \\non the subset of input data and testing on previously unseen subset of the input \\ndata.  We can also say that it is a technique to check how a statistical model \\ngeneralizes to an independent dataset . \\nIn machine learning , there is always the need to test the stability of the model. \\nIt means based only on the training dataset; we can\\'t fit our model on the \\ntraining dataset. For this purpose, we reser ve a particular sample of the dataset, \\nwhich was not part of the training dataset. After that, we test our model on that \\nsample before deployment, and this complete process comes under cross -\\nvalidation. This is something different from the general train -test split.  \\nHence the basic steps of cross -validations are:  \\no Reserve a subset of the dataset as a validation set.  \\no Provide the training to the model using the training dataset.  \\no Now, evaluate model performance using the validation set. If the model \\nperforms wel l with the validation set, perform the further step, else check \\nfor the issues.  \\nMethods used for Cross -Validation  \\nThere are some common methods that are used for cross -validation. These \\nmethods are given below:  \\n1. Validation Set Approach  \\n2. Leave -P-out cross -validation  \\n3. Leave one out cross -validation  \\n4. K-fold cross -validation  \\n5. Stratified k -fold cross -validation  \\nValidation Set Approach  \\nWe divide our input dataset into a training set and test or validation set in the \\nvalidation set approach. Both the subsets a re given 50% of the dataset.  \\nBut it has one of the big disadvantages that we are just using a 50% dataset to \\ntrain our model, so the model may miss out to capture important information \\nof the dataset. It also tends to give the underfitted model.  \\nLeave -P-out cross -validation  \\nIn this approach, the p datasets are left out of the training data. It means, if there \\nare total n datapoints in the original input dataset, then n -p data points will be \\nused as the training dataset and the p data points as the validatio n set. This complete process is repeated for all the samples, and the average error is \\ncalculated to know the effectiveness of the model.  \\nThere is a disadvantage of this technique; that is, it can be computationally \\ndifficult for the large p.  \\nLeave one out  cross -validation  \\nThis method is similar to the leave -p-out cross -validation, but instead of p, we \\nneed to take 1 dataset out of training. It means, in this approach, for each \\nlearning set, only one datapoint is reserved, and the remaining dataset is used \\nto train the model. This process repeats for each datapoint. Hence for n samples, \\nwe get n different training set and n test set. It has the following features:  \\no In this approach, the bias is minimum as all the data points are used.  \\no The process is executed for n times; hence execution time is high.  \\no This approach leads to high variation in testing the effectiveness of the \\nmodel as we iteratively check against one data point.  \\nK-Fold Cross -Validation  \\nK-fold cross -validation approach divides the input dataset into K groups of \\nsamples of equal sizes. These samples are called  folds . For each learning set, the \\nprediction function uses k -1 folds, and the rest of the folds are used for the test \\nset. This approach is a very popular CV approach because it is easy to \\nunderstand, and the output is less biased than other methods.  \\nThe steps for k -fold cross -validation are:  \\no Split the input dataset into K groups  \\no For each group:  \\no Take one group as the reserve or test data set.  \\no Use remaining groups as the training dataset  \\no Fit the model on the training set and evaluate the performance of \\nthe model using the test set.  \\nLet\\'s take an example of 5 -folds cross -validation. So, the dataset is grouped into \\n5 folds. On 1st iteration, the first fold is reserved for test the model, and res t are \\nused to train the model. On 2nd iteration, the second fold is used to test the model, and rest are used to train the model. This process will continue until each \\nfold is not used for the test fold.  \\nConsider the below diagram:  \\n \\nStratified k -fold cros s-validation  \\nThis technique is similar to k -fold cross -validation with some little changes. This \\napproach works on stratification concept, it is a process of rearranging the data \\nto ensure that each fold or group is a good representative of the complete \\ndataset. To deal with the bias and variance, it is one of the best approaches.  \\nIt can be understood with an example of housing prices, such that the price of \\nsome houses can be much high than other houses. To tackle such situations, a \\nstratified k -fold cross -validation technique is useful.  \\nHoldout Method  \\nThis method is the simplest cross -validation technique among all. In this \\nmethod, we need to remove a subset of the training data and use it to get \\nprediction results by training it on the rest part of the da taset.  \\nThe error that occurs in this process tells how well our model will perform with \\nthe unknown dataset. Although this approach is simple to perform, it still faces \\nthe issue of high variance, and it also produces misleading results sometimes.  \\nApplicati ons of Cross -Validation  \\no This technique can be used to compare the performance of different \\npredictive modeling methods.  \\no It has great scope in the medical research field.  \\no It can also be used for the meta -analysis, as it is already being used by the \\ndata scientists in the field of medical statistics . \\nBootstrap  \\nBootstrap is a resampling technique widely used in machine learning and statistics for \\nestimating the uncertainty associated with a sample statistic or model parameter. It involves \\nrandomly sampling data points with replacement from the original dataset to create \\nmultiple bootstrap samples, which are then used to assess the stability and reliability of a \\nstatistical estimate or model.  \\n \\nHere\\'s how bootstrap works in machine learning:  \\n \\nSampling with Rep lacement:  Given an original dataset of size  \\n  \\nN, bootstrap sampling involves randomly selecting  \\n  \\nN data points from the dataset with replacement. This means that each data point has an \\nequal chance of being selected multiple times or not at all in each bootstrap sample.  \\n \\nCreating Bootstrap Samples:  By repeating the sampling process multiple times (often \\nthousands of times), multiple bootstrap samples are generated, each of the same size as the \\noriginal dataset.  \\n \\nEstimating Uncertainty:  These bootstrap sa mples are then used to estimate the uncertainty \\nassociated with a statistic or model parameter of interest. For example:  \\n \\nParameter Estimation:  If you\\'re interested in estimating a population parameter (e.g., mean, \\nmedian, standard deviation), you can comp ute the statistic of interest for each bootstrap \\nsample and then examine the distribution of these statistics across all bootstrap samples to \\nquantify uncertainty.  \\nModel Performance: In the context of machine learning, bootstrap can be used to estimate \\nthe variability of performance metrics such as accuracy, precision, recall, or AUC (Area Under \\nthe ROC Curve). For each bootstrap sample, you can train your model and evaluate its \\nperformance, then analyze the distribution of performance metrics across all bo otstrap \\nsamples.  \\nConfidence Intervals:  Bootstrap provides a straightforward way to compute confidence \\nintervals for the estimated statistic or performance metric. Confidence intervals give a range \\nof values within which the true parameter or metric is like ly to lie with a certain level of \\nconfidence.  \\n \\nModel Selection and Validation:  Bootstrap can also be used for model selection and \\nvalidation. For example, in bootstrap aggregating (bagging), multiple models are trained on \\ndifferent bootstrap samples, and their predictions are combined to reduce overfitting and \\nimprove generalization . \\n \\nBootstrap is particularly useful when analytical methods for estimating uncertainty are \\ncomplex or unavailable. It\\'s computationally intensive but can provide robust estimates of uncertainty and model performance, especially in scenarios with limited da ta or when \\ndealing with nonparametric models.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT-4  \\nCLUSTERING:  Basic Clustering Methods: Partitional Clustering, Hierarchical \\nClustering, K -Means Clustering. Expectation -Maximization (EM) Algorithm and \\nGaussian Mixtures Clustering  \\nINTRODUCTION TO  NEURAL NETWORKS:  Neural Network \\nRepresentations, Appropriate Problems for Neural Network Learning, \\nPerceptrons, Multilayer Networks and the Back propagation Algorithm, \\nRemarks on Back Propagation Algorithm  \\nBasic Clustering Methods:  \\n Clustering  is the task of grouping a set of customers in such a way that customers in the same \\ngroup (called a  cluster ) are more similar (in some sense) to each other than to those in other \\ngroups (clusters). Cluster analysis uses mathematical models to di scover groups of similar \\ncustomers based on the smallest variations among customers within each group. A Clustering \\nAlgorithm tries to analyse natural groups of data on the basis of some similarity. It locates the \\ncentroid of the group of data points. To c arry out effective clustering, the algorithm evaluates \\nthe distance between each point from the centroid of the cluster. The goal of clustering is to \\ndetermine the intrinsic grouping in a set of unlabelled data i.e. data without any dependent \\nvariable.  \\n \\nClustering is dividing data points into homogeneous classes or clusters:  \\n\\uf0b7 Points in the same group are as similar as possible  \\n\\uf0b7 Points in different group are as dissimilar as possible  \\nApplications of Clustering - \\n\\uf0b7 Clustering helps marketers improve their customer base and work on the target \\nareas. It helps group people (according to different criteria’s such as willingness, \\npurchasing power etc.) based on their similarity in many ways related to the \\nproduct under consideration.  \\n\\uf0b7 Clustering helps in identification of groups of houses on the basis of their value, \\ntype and geographical locations.  \\n\\uf0b7 Clustering is used to study earth -quake. Based on the areas hit by an earthquake \\nin a region, clustering can help analyse the next probable location where \\nearthquake can occur.  \\n \\nPartitional Clustering : \\nIt is a type of clustering that divides the data into non -hierarchical groups. It is also \\nknown as the  centroid -based method . The most common example of partitioning \\nclustering is the  K-Means Clustering algorithm . \\nIn this type, the dataset is divided into a set of k groups, where K is used to define the \\nnumber of pre -defined groups. The cluster center is created in such a wa y that the \\ndistance between the data points of one cluster is minimum as compared to another \\ncluster centroid.  \\nPartitioning Algorithms used in Clustering – \\n \\n \\nTypes of Partitional Clustering  \\nK-Means Algorithm (A centroid based Technique):  It is one of the most commonly \\nused algorithm for partitioning a given data set into a set of k groups (i.e.  k clusters ), where k \\nrepresents the number of groups. It classifies objects in multiple groups (i.e., clusters), such \\nthat objects within the same cluster are as si milar as possible (i.e., high  intra -class similarity ), \\nwhereas objects from different clusters are as dissimilar as possible (i.e., low  inter -class \\nsimilarity ). In k -means clustering, each cluster is represented by its center (i.e,  centroid ) \\nwhich corresponds to the mean of points assigned to the cluster. The basic idea behind k -\\nmeans clustering consists of defining clusters so that the total intra -cluster variation (known \\nas total within -cluster variation) is minimized.  \\n \\n \\nProcess for K -means Algor ithm  \\nSteps involved in K -Means Clustering :  \\n1. The first step when using k -means clustering is to indicate the number of clusters \\n(k) that will be generated in the final solution.  \\n2. The algorithm starts by randomly selecting k objects from the data set to serve as \\nthe initial centers for the clusters. The selected objects are also known as cluster \\nmeans or centroids.  \\n3. Next, each of the remaining objects is assigned to it’s closest cent roid, where \\nclosest is defined using the  Euclidean distance  between the object and the \\ncluster mean. This step is called “cluster assignment step”.  \\n4. After the ass ignment step, the algorithm computes the new mean value of each \\ncluster. The term cluster “centroid update” is used to design this step. Now that \\nthe centers have been recalculated, every observation is checked again to see if \\nit might be closer to a diffe rent cluster. All the objects are reassigned again using \\nthe updated cluster means.  \\n5. The cluster assignment and centroid update steps are iteratively repeated until \\nthe cluster assignments stop changing (i.e until  convergence  is achieved). That is, \\nthe clus ters formed in the current iteration are the same as those obtained in the \\nprevious iteration  \\nK-Medoids Algorithm (Partitioning Around Medoid) :  \\n1. A medoid can be defined as the point in the cluster, whose similarities with all \\nthe other points in the cluster is maximum.  \\n2. In k-medoids clustering, each cluster is represented by one of the data point in \\nthe cluster. These points are named cluster medoids. The term medoid refers to \\nan object within a cluster for which average dissimilarity between it and al l the \\nother the members of the cluster is minimal. It corresponds to the most centrally \\nlocated point in the cluster.  3. These objects (one per cluster) can be considered as a representative example of \\nthe members of that cluster which may be useful in some s ituations. Recall that, \\nin k-means clustering, the center of a given cluster is calculated as the mean \\nvalue of all the data points in the cluster.  \\n4. K-medoid is a robust alternative to k -means clustering. This means that, the \\nalgorithm is less sensitive to noise and outliers, compared to k -means, because it \\nuses medoids as cluster centers instead of means (used in k -means).  \\n \\n \\nSteps involved in K -Medoid Clustering  \\nSteps involved in K -Medoids Clustering :  \\n1. The PAM algorithm is based on the search for k representative objects or \\nmedoids among the observations of the data set.  \\n2. After finding a set of k medoids, clusters are constructed by assigning each \\nobservation to the nearest medoid.  \\n3. Next, each selected medoid m and each non -medoid data point are swappe d and \\nthe objective function is computed. The objective function corresponds to the \\nsum of the dissimilarities of all objects to their nearest medoid.  \\n4. The SWAP step attempts to improve the quality of the clustering by exchanging \\nselected objects (medoids) and non -selected objects. If the objective function \\ncan be reduced by interchanging a selected object with an unselected object, \\nthen the swap is carri ed out. This is continued until the objective function can no \\nlonger be decreased. The goal is to find k representative objects which minimize \\nthe sum of the dissimilarities of the observations to their closest representative \\nobject.  \\n \\nHierarchical Clusteri ng : \\nHierarchical clustering is another unsupervised machine learning algorithm, \\nwhich is used to group the unlabeled datasets into a cluster and also known \\nas hierarchical cluster analysis  or HCA.  \\nIn this algorithm, we develop the hierarchy of clusters in  the form of a tree, and \\nthis tree -shaped structure is known as the  dendrogram . \\nSometimes the results of K -means clustering and hierarchical clustering may \\nlook similar, but they both differ depending on how they work. As there is no \\nrequirement to predete rmine the number of clusters as we did in the K -Means \\nalgorithm.  \\nThe hierarchical clustering technique has two approaches:  \\n1. Agglomerative:  Agglomerative is a  bottom -up approach, in which the \\nalgorithm starts with taking all data points as single clusters and merging them \\nuntil one cluster is left.  \\n2. Divisive:  Divisive algorithm is the reverse of the agglomerative algorithm as it \\nis a top-down approach.  \\nAgglomerative Hierarchical clustering  The agglomerative hierarchical clustering algorithm is a popular example of HCA. To \\ngroup the datasets into clusters, it follows the  bottom -up approach . It means, this \\nalgorithm considers each dataset as a single cluster at the begi nning, and then start \\ncombining the closest pair of clusters together. It does this until all the clusters are \\nmerged into a single cluster that contains all the datasets.  \\nThis hierarchy of clusters is represented in the form of the dendrogram.  \\nHow the Agg lomerative Hierarchical clustering Work?  \\nThe working of the AHC algorithm can be explained using the below steps:  \\nStep -1: Create each data point as a single cluster. Let\\'s say there are N data points, so the \\nnumber of clusters will also be N.  \\n \\nStep -2: Take two closest data points or clusters and merge them to form one cluster. So, \\nthere will now be N -1 clusters.  \\n \\nStep -3: Again, take the two closest clusters and merge them together to form one cluster. \\nThere will be N -2 clusters.  \\n \\no Step -4: Repeat Step 3  until only one cluster left. So, we will get the following \\nclusters. Consider the below images:  \\n \\n \\n \\no Step -5: Once all the clusters are combined into one big cluster, develop the \\ndendrogram to divide the clusters as per the problem.  \\nWoking of Dendrogram in Hierarchical clustering  \\nThe dendrogram is a tree -like structure that is mainly used to store each step as a \\nmemory that the HC algorithm performs. In the dendrogram plot, the Y -axis shows the \\nEuclidean distances between the data points, and the x -axis s hows all the data points \\nof the given dataset.  \\nThe working of the dendrogram can be explained using the below diagram:  \\n \\nIn the above diagram, the left part is showing how clusters are created in \\nagglomerative clustering, and the right part is showing the corresponding \\ndendrogram.  \\no As we have discussed above, firstly, the datapoints P2 and P3 combine together and \\nform a cluster, correspondingly a dendrogram is created, which connects P2 and P3 \\nwith a rectangular shape. The hight is decided according to the E uclidean distance \\nbetween the data points.  \\no In the next step, P5 and P6 form a cluster, and the corresponding dendrogram is \\ncreated. It is higher than of previous, as the Euclidean distance between P5 and P6 is a \\nlittle bit greater than the P2 and P3.  \\no Again , two new dendrograms are created that combine P1, P2, and P3 in one \\ndendrogram, and P4, P5, and P6, in another dendrogram.  \\no At last, the final dendrogram is created that combines all the data points together.  \\nWe can cut the dendrogram tree structure at any  level as per our requirement.  \\nDivisive Hierarchical Clustering:  \\n\\uf0b7 Divisive hierarchical clustering starts with all data points in one cluster.  \\n\\uf0b7 It then recursively splits the cluster into smaller clusters until each cluster \\ncontains only one data point.  \\n\\uf0b7 Divisive hierarchical clustering requires defining a stopping criterion to \\ndetermine when to stop splitting clusters.  \\n\\uf0b7 Unlike agglomerative clustering, divisive clustering can be computationally \\nexpensive, especially for large datasets, as it needs to evaluate all possible \\nsplits at each step.  \\n                 \\nAdvantages of Hierarchical Clustering:  \\n\\uf0b7 No need to specify the number of clusters in advance.  \\n\\uf0b7 Provides a visual representation of the clustering process through \\ndendrograms.  \\n\\uf0b7 The ability to handle missing data and noisy data.  \\n\\uf0b7 Suitable for datasets with complex structures or when the underlying hierarchy \\nis of interest.  \\n \\nK-Means Clustering Algorithm  \\nK-Means Clustering is an unsupervised learning algorithm that is used to solve the clustering \\nproblems in machine learning or data science. In this topic, we will learn what is K -means \\nclustering algorithm, how the algorithm works, along with the Python implementation of k -\\nmeans clustering.  \\nWhat is K -Means Algorithm?   \\nK-Means Clustering is an  Unsupervised Learning algorithm , which groups the unlabeled \\ndataset into different clusters. Here K defines the number of pre -defined clusters that need \\nto be created in the process, as if K=2, there will be two clusters, and for K=3, there will be \\nthree clusters, and so on.  \\nIt is an iterative algorithm that divides the unlabeled dataset into k different clusters in such \\na way that each dataset belongs only one group that has similar properties.  \\nIt all ows us to cluster the data into different groups and a convenient way to dis    \\ncover the categories of groups in the unlabeled dataset on its own without the need for any \\ntraining.  \\nIt is a centroid -based algorithm, where each cluster is associated with a c entroid. The main \\naim of this algorithm is to minimize the sum of distances between the data point and their \\ncorresponding clusters.  \\nThe algorithm takes the unlabeled dataset as input, divides the dataset into k -number of \\nclusters, and repeats the process until it does not find the best clusters. The value of k should \\nbe predetermined in this algorithm.  \\nThe k -means  clustering  algorithm mainly performs two tasks:  \\no Determines the best va lue for K center points or centroids by an iterative process.  \\no Assigns each data point to its closest k -center. Those data points which are near to the \\nparticular k -center, create a cluster.  \\nHence each cluster has datapoints with some commonalities, and it is away from other \\nclusters.  \\nThe below diagram explains the working of the K -means Clustering Algorithm :  \\nHow does the K -Means Algorithm Work?  \\nThe working of the K -Means algorithm is explained in the below steps:  \\nStep -1: Select the number K to decide the number of clusters.  \\nStep -2: Select random K points or centroids. (It can be other from the input dataset).  \\nStep -3: Assign each data point to their closest centroid, which will form the predefined K \\nclusters.  \\nStep -4: Calculate the variance and place a new c entroid of each cluster.  \\nStep -5: Repeat the third steps, which means reassign each datapoint to the new closest \\ncentroid of each cluster.  \\nStep -6: If any reassignment occurs, then go to step -4 else go to FINISH.  \\nStep -7: The model is ready.  \\n \\n(1, 2), (2, 1), (2, 3), (3, 2), (6, 8), (7, 7), (8, 9), (9, 8)  \\nLet\\'s go through the steps for our example:  \\n1. Initialization : Let\\'s randomly choose two initial centroids: (2, 1) and (8, 9).  \\n2. Assign  Points  to Clusters : \\n\\uf0b7 (1, 2) is closer to (2, 1) than to (8, 9), so it belongs to the first cluster.  \\n\\uf0b7 (2, 1) itself belongs to the first cluster.  \\n\\uf0b7 (2, 3) belongs to the first cluster.  \\n\\uf0b7 (3, 2) belongs to the first cluster.  \\n\\uf0b7 (6, 8) is closer to (8, 9) than to (2, 1), so it belongs to the second cluster.  \\n\\uf0b7 (7, 7) belongs to the second cluster . \\n\\uf0b7 (8, 9) itself belongs to the second cluster.  \\n\\uf0b7 (9, 8) belongs to the second cluster.  \\n3. Update  Centroids : \\n\\uf0b7 The centroid of the first cluster becomes the mean of its points: \\n(1+2+2+3)/4 = (8/4, 8/4) = (2, 2)  \\n\\uf0b7 The centroid of the second cluster becomes the mean o f its points: \\n(6+7+8+9)/4 = (30/4, 32/4) = (7.5, 8)  \\n4. Repeat : \\n\\uf0b7 We repeat steps 2 and 3 until the centroids no longer change \\nsignificantly.  \\nAfter a few iterations, the centroids stabilize:  \\n\\uf0b7 Cluster 1: (1, 2), (2, 1), (2, 3), (3, 2)  \\n\\uf0b7 Cluster 2: (6, 8), (7, 7), (8, 9), (9, 8)  \\nThese are the final clusters obtained through K -means clustering.  \\n \\nAdvantages of k -means  \\n1. Simple and easy to implement: The k -means algorithm is easy to understand and \\nimplement, making it a popular choice for clustering tasks.  \\n2. Fast and efficient: K -means is computationally efficient and can handle large \\ndatasets with high dimensionality.  \\n3. Scalability: K -means can handle large datasets with a large number of data points \\nand can be easily scaled to handle even larger datasets.  \\n4. Flexibility: K-means can be easily adapted to different applications and can be \\nused with different distance metrics and initialization methods.  \\nDisadvantages of K -Means:  \\n1. Sensitivity to initial centroids: K -means is sensitive to the initial selection of \\ncentroids and c an converge to a suboptimal solution.  \\n2. Requires specifying the number of clusters: The number of clusters k needs to be \\nspecified before running the algorithm, which can be challenging in some \\napplications.  \\n3. Sensitive to outliers: K -means is sensitive to out liers, which can have a significa nt \\nimpact on the resulting clusters.  Applications of K -Means Clustering  \\nK-Means clustering is used in a variety of examples or business cases in real life, like:  \\n\\uf0b7 Academic performance   \\n\\uf0b7 Diagnostic systems   \\n\\uf0b7 Search engines   \\n\\uf0b7 Wireless sensor networks  \\nExpectation -Maximization (EM) Algorithm  \\n \\nThe Expectation -Maximization (EM) algorithm is an iterative optimization method that \\ncombines different  unsupervised  machine  learning  algorithms to find maximum likelihood \\nor maximum posterior estimates of parameters in statistical models that involve \\nunobserved latent variables. The EM algorithm is commonly used for latent variable \\nmodels and can handle missing data. It consists of an estimation step (E -step) and a \\nmaximization step ( M-step), forming an iterative process to improve model fit.  \\n\\uf0b7 In the E step, the algorithm computes the latent variables i.e. expectation of the \\nlog-likelihood using the current parameter estimates.   \\n\\uf0b7 In the M step, the algorithm determines the parameters tha t maximize the \\nexpected log -likelihood obtained in the E step, and corresponding model \\nparameters are updated based on the estimated latent variables.   \\n \\n \\nExpectation -Maximization in EM Algorithm  \\nBy iteratively repeating these steps, the EM algorithm seeks  to maximize the likelihood of \\nthe observed data. It is commonly used for unsupervised learning tasks, such as clustering, \\nwhere latent variables are inferred and has applications in various fields, including \\nmachine learning, computer vision, and natural language processing.  \\nKey Terms in Expectation -Maximization (EM) Algorithm  \\nSome of the most commonly used key terms in the Expectation -Maximization (EM) \\nAlgorithm are as follows:  \\n\\uf0b7 Latent  Variables:  Latent variables are unobserved variables in statistical mod els \\nthat can only be inferred indirectly through their effects on observable \\nvariables. They cannot be directly measured but can be detected by their \\nimpact on the observable variables.  \\n\\uf0b7 Likelihood:  It is the probability of observing the given data given th e parameters \\nof the model. In the EM algorithm, the goal is to find the parameters that \\nmaximize the likelihood.  \\n\\uf0b7 Log-Likelihood:  It is the logarithm of the likelihood function, which measures the \\ngoodness of fit between the observed data and the model. EM algorithm seeks \\nto maximize the log -likelihood.  \\n\\uf0b7 Maximum  Likelihood  Estimation  (MLE) : MLE is a method to estimate the \\nparameters of a statistical model by finding the parameter values that maximize \\nthe likelihood function, which measures how well the model explains the \\nobserved data.  \\n\\uf0b7 Posterior  Probability : In the context of Bayesian inference, the EM algorithm can \\nbe extended to estimate the maximum a posteriori (MAP) estimates, where the \\nposterior probability of the parameters is calculated based on the pri or \\ndistribution and the likelihood function.  \\n\\uf0b7 Expectation  (E) Step : The E -step of the EM algorithm computes the expected \\nvalue or posterior probability of the latent variables given the observed data \\nand current parameter estimates. It involves calculating the probabilities of \\neach latent variable for each data point.  \\n\\uf0b7 Maximization  (M) Step : The M -step of the EM algorithm updates the parameter \\nestimates by maximizing the expected log -likelihood obtained from the E -step. \\nIt involves finding the parameter value s that optimize the likelihood function, \\ntypically through numerical optimization methods.  \\n\\uf0b7 Convergence:  Convergence refers to the condition when the EM algorithm has \\nreached a stable solution. It is typically determined by checking if the change in \\nthe log -likelihood or the parameter estimates falls below a predefined \\nthreshold . \\nHow Expectation -Maximization (EM)  Algorithm Works:  \\nThe essence of the Expectation -Maximization algorithm is to use the available observed \\ndata of the dataset to estimate the missin g data and then use that data to update the \\nvalues of the parameters. Let us understand the EM algorithm in detail.  \\n  \\nEM Algorithm Flowchart  \\nInitialization:  \\nInitially, a set of initial values of the parameters are considered. A set of incomplete \\nobserved data is given to the system with the assumption that the observed data comes \\nfrom a specific model.  \\nE-Step  (Expectation  Step):  In this step, we use the observed data in order to estimate or \\nguess the values of the missing or incomplete data. It is basicall y used to update the \\nvariables.   \\n\\uf0b7 Compute the posterior probability or responsibility of each latent \\nvariable given the observed data and current parameter estimates.  \\n\\uf0b7 Estimate the missing or incomplete data values using the current \\nparameter estimates.  \\n\\uf0b7 Comp ute the log -likelihood of the observed data based on the \\ncurrent parameter estimates and estimated missing data.  \\nM-step  (Maximization  Step):  In this step, we use the complete data generated in the \\npreceding “Expectation ” – step in order to update the value s of the parameters. It is \\nbasically used to update the hypothesis.  \\n\\uf0b7 Update the parameters of the model by maximizing the expected \\ncomplete data log -likelihood obtained from the E -step.  \\n\\uf0b7 This typically involves solving optimization problems to find the \\nparam eter values that maximize the log -likelihood.  \\n\\uf0b7 The specific optimization technique used depends on the nature of \\nthe problem and the model being used.  \\nConvergence : In this step, it is checked whether the values are converging or not, if yes, \\nthen stop other wise repeat  step -2 and step -3 i.e. “Expectation ” – step and “Maximization ” \\n– step until the convergence occurs.  \\n\\uf0b7 Check for convergence by comparing the change in log -likelihood or \\nthe parameter values between iterations.  \\n\\uf0b7 If the change is below a predefined threshold, stop and consider the \\nalgorithm converged.  \\n\\uf0b7 Otherwise, go back to the E -step and repeat the process until \\nconvergence is achieved.  \\nGaussian Mixtures Clustering   \\nGaussian Mixture Models (GMMs) are a probabilistic model used for clustering in machi ne learning. \\nUnlike some other clustering algorithms that assign data points to a single cluster, GMMs assign each \\ndata point a probability of belonging to each cluster. This makes them flexible and capable of \\ncapturing complex cluster shapes and structure s. \\n \\nHere\\'s how Gaussian Mixture Models work:  \\n \\nModel Representation:  A Gaussian Mixture Model represents the probability distribution of the \\nentire dataset as a weighted sum of multiple Gaussian distributions (also known as components or \\nclusters). Each Gaussian component is characterized by its mean vector and covariance matrix, \\nrepresenting the center and shape of the cluster.  \\n \\nInitialization:  The algorithm starts with an initial guess of the parameters, including the means, \\ncovariances, and mixing coefficients (weights) for each component. Initialization can be done \\nrand omly or using techniques like K -means clustering.  \\n \\nExpectation -Maximization (EM) Algorithm:  GMMs are typically trained using the Expectation -\\nMaximization (EM) algorithm, which alternates between two steps:  \\n \\nExpectation (E -step):  In this step, for each data  point, the algorithm computes the probability \\n(responsibility) of belonging to each cluster based on the current model parameters.  \\n \\nMaximization (M -step):  In this step, the algorithm updates the parameters (mean, covariance, and \\nmixing coefficients) of ea ch Gaussian component based on the current assignments computed in the \\nE-step.  \\nConvergence:  The EM algorithm iterates between the E -step and M -step until convergence, where \\nthe parameters no longer change significantly or a predefined number of iterations is reached.  \\n \\nCluster Assignment:  Once the model is trained, each data point is assigned to the cluster with the \\nhighest probability (or a threshold can be applied for hard assignments).  \\n \\nKey points about Gaussian Mixture Models:  \\n \\nSoft Clustering: GMMs prov ide soft assignments, meaning they assign each data point a probability \\nof belonging to each cluster. This allows GMMs to capture the uncertainty in cluster assignments, \\nwhich can be particularly useful in scenarios where data points lie near the boundarie s between \\nclusters.  \\n \\nCluster Shape: Unlike K -means, which assumes spherical clusters, GMMs can model clusters with \\ndifferent shapes and orientations by adjusting the covariance matrices of the Gaussian components. \\nThis makes GMMs more flexible and capable of capturing complex data distributions.  \\n \\nNumber of Components: Similar to other clustering algorithms, determining the optimal number of \\ncomponents (clusters) in a GMM is important. Techniques such as the Akaike Information Criterion \\n(AIC) or Bayesian Inf ormation Criterion (BIC) can be used for model selection.  \\n Initialization Sensitivity: GMMs can be sensitive to initialization, and different initializations may lead \\nto different solutions. Thus, it\\'s common to run the algorithm multiple times with differ ent \\ninitializations and choose the best solution based on some criterion.  \\n \\nGaussian Mixture Models are widely used in various applications, including image segmentation, \\ndensity estimation, and anomaly detection, where the underlying data distribution is a ssumed to be \\na mixture of Gaussian components.  \\nNeural Network Representations:  \\nA neural network can be understood as a network of hidden layers, an input layer and an \\noutput layer that tries to mimic the working of a human brain.  \\nThe hidden layers can be visualized as an abstract representation of the input data itself. These \\nlayers help the neural network understand various features of the data with the help of its \\nown internal logic.  \\nThese neural networks are non -interpretable models. Non -interpretable m odels are those \\nwhich can ’t be interpreted or understood even if we observe the hidden layers. This is because \\nthe neural networks have an internal logic working on its own, that can ’t be comprehended \\nby us.  \\nWe can just see then as a vector of numerical va lues. Since the output of a neural network is \\na numerical vector, we need to have an explicit output layer that bridges the gap between the \\nactual data and the representation of the data by the network.  \\nAn output layer can be understood as a translator tha t helps us to understand the logic of the \\nnetwork and convert the target values.  \\nA theorem named ‘Universal approximation theorem ’ tells that a feedforward network that \\ncontains one hidden layer can be used to represent any function.  \\nThis means there is no  limit on the functioning of a neural network that contains one hidden \\nlayer. But in real life situations, a neural network with one hidden layer can ’t be used well.  \\nA neural network is a mathematical model that helps in processing information. It is not a  set \\nof lines of code, but a model or a system that helps process the inputs/information and gives \\nresult.  \\nThe information is processed in the simplest form over basic elements known as ‘neurons ’. \\nNeurons are connected and help exchange signals/information  between them with the help \\nof connection links.  This connection links between neurons could be strong or weak, and this strength of the \\nconnection links determines the method in which information is processed.  \\nEvery neuron has an internal state which can be determined by the incoming connections \\nfrom other neurons.  \\nEvery neuron has an activation function which is calculated on its state, and this helps \\ndetermine its output signal.  \\nA neural network can be understood as a computational graph of mathematical operations.  \\nTwo main characteristics of a neural network − \\n\\uf0b7 Architecture  \\n\\uf0b7 Learning  \\nArchitecture  \\nIt tells about the connection type: whether it is feedforward, recurrent, multi -layered, \\nconvolutional, or single layered. It also tells about the number of layers and the number of \\nneurons in every layer.  \\nLearning  \\nIt tells about the method in which the neural network is trained. A common way to train a \\nneural network is to use gradient descent and backpropagation.  \\nAppropriate Problems for Neural Network Learn ing \\n \\nNeural networks, being versatile and powerful models, can be applied to various problem \\ndomains in machine learning. The suitability of a neural network for a particular problem \\ndepends on factors such as the availability of data, the complexity of th e problem, and the \\ndesired output. Here are some common problem types where neural networks are often \\nused:  \\n \\nClassification:  \\n \\nImage classification: Given an image, classify it into predefined categories (e.g., cat, dog, \\ncar).  \\nText classification: Classify text documents into predefined categories (e.g., spam detection, \\nsentiment analysis).  \\nSpeech recognition: Identify spoken words or phrases from audio data.  \\nMedical diagnosis: Diagnose diseases based on medical images (e.g., X -rays, MRI scans).  \\nRegression:   \\nPredicting house prices: Given features of a house (e.g., size, number of bedrooms), predict \\nits selling price.  \\nStock price prediction: Forecast future stock prices based on historical data and other \\nfactors.  \\nDemand forecasting: Predict future demand for products or services based on historical \\nsales data and external factors.  \\nSequence Modeling:  \\n \\nLanguage translation: Translate text from one language to another.  \\nSpeech synthesis: Generate human -like speech from text input.  \\nTime series prediction: Forecast future values based on past observations (e.g., weather \\nforecasting, sales prediction).  \\nAnomaly Detection:  \\n \\nFraud detection: Identify fraudulent transactions or activities in financial transactions.  \\nIntrusion detection: Detect abnormal behavior or attacks in computer networks.  \\nGenerative Modeling:  \\n \\nImage generation: Generate realistic images from random noise (e.g., Generative Adversarial \\nNetworks - GANs).  \\nText generation: Generate human -like text (e.g., chatbots, story generation).  \\nMusic generation: Compos e new music pieces based on existing compositions.  \\nReinforcement Learning:  \\n \\nGame playing: Train agents to play video games or board games.  \\nRobotics: Train robots to perform tasks in simulated or real environments.  \\nDimensionality Reduction:  \\n \\nFeature extraction: Reduce the dimensionality of high -dimensional data while preserving \\nrelevant information (e.g., for visualization or speeding up subsequent processing).  \\nCombination Problems:  \\n \\nMulti -task learning: Learn multiple tasks simultaneously, sharing in formation across tasks to \\nimprove performance.  \\nTransfer learning: Pre -train a neural network on one task and then fine -tune it on a related \\ntask with limited data.  \\nThese are just a few examples, and neural networks can be adapted to many other types of \\nproblems as well. The key is to understand the nature of the data and the problem at hand \\nand choose or design an appropriate neural network architecture and training approach \\naccordingly.  \\n \\nPerceptron : \\nIn Machine Learning and Artificial Intelligence, Perceptr on is the most commonly used term \\nfor all folks. It is the primary step to learn Machine Learning and Deep Learning \\ntechnologies, which consists of a set of weights, input values or scores, and a \\nthreshold.  Perceptron is a building block of an Artificial N eural Network . Initially, in the mid of 19th century,  Mr. Frank Rosenblatt  invented the Perceptron for performing certain \\ncalculations to detect input data capabilities or business intelligence. Perceptron is a linear \\nMachine Learning algorithm used for supervised learning for various binary classifiers. This \\nalgorithm enables neurons to learn elements and processes them one by one during \\npreparation. In this tutorial, \"Perceptron in Machine Learning,\" we will discuss in -depth \\nknowledge of Perceptron and its basic functions in brief. Let\\'s start with the basic \\nintroduction of Perceptron  \\nWhat is the Perceptron model in Machine Learning?  \\nPerceptron is Machine Learning algorithm for supervised learning of various binary \\nclassification tasks. Further,  Perceptr on is also understood as an Artificial Neuron or neural \\nnetwork unit that helps to detect certain input data computations in business intelligence . \\nPerceptron model is also treated as one of the best and simplest types of Artificial Neural \\nnetworks. Howeve r, it is a supervised learning algorithm of binary classifiers. Hence, we can \\nconsider it as a single -layer neural network with four main parameters, i.e.,  input values, \\nweights and Bias, net sum, and an activation function.  \\nWhat is Binary classifier in Ma chine Learning?  \\nIn Machine Learning, binary classifiers are defined as the function that helps in deciding \\nwhether input data can be represented as vectors of numbers and belongs to some specific \\nclass.  \\nBinary classifiers can be considered as linear classi fiers. In simple words, we can understand \\nit as a  classification algorithm that can predict linear predictor function in terms of weight and \\nfeature vectors.  \\nBasic Components of Perceptron  \\nMr. Frank Rosenblatt invented the perceptron model as a binary clas sifier which contains \\nthree main components. These are as follows:   \\no Input Nodes or Input Layer:  \\nThis is the primary component of Perceptron which accepts the initial data into the system for \\nfurther processing. Each input node contains a real numerical value.  \\no Wight and Bias:  \\nWeight parameter represents the strength of the connection between units. This is another \\nmost important parameter of Perceptron components. Weight is directly proportional to the \\nstrength of the associated input neuron in deciding the output. Further, Bias can be \\nconsidered as the line of intercept in a linear equation.  \\no Activation Function:  \\nThese are the final and important components that help to determine whether the neuron \\nwill fire or not. Activation Function can be considered p rimarily as a step function.  \\nTypes of Activation functions:  \\no Sign function  \\no Step function, and  \\no Sigmoid function  \\n \\nThe data scientist uses the activation function to take a subjective decision based on various \\nproblem statements and forms the desired outputs.  Activation function may differ (e.g., Sign, \\nStep, and Sigmoid) in perceptron models by checking whether the learning process is slow or \\nhas vanishing or exploding gradients.  \\nHow does Perceptron work?  \\nIn Machine Learning, Perceptron is considered as a single -layer neural network that consists \\nof four main parameters named input values (Input nodes), weights and Bias, net sum, and an \\nactivation function. The perceptron model begins with the multiplication of all input values \\nand their weights, then adds these values together to create the weighted sum. Then this \\nweighted sum is applied to the activation function \\'f\\' to obtain the desired output. This \\nactivation function is also known as the  step function  and is represented by  \\'f\\'. \\n \\nThis step function or Activation function plays a vital role in ensuring that output is mapped \\nbetween required values (0,1) or ( -1,1). It is important to note that the weight of input is \\nindicative of the strength of a node. Similarly, an input\\'s bias value gives the ability t o shift the \\nactivation function curve up or down.  \\nPerceptron model works in two important steps as follows:  \\nStep -1 \\nIn the first step first, multiply all input values with corresponding weight values and then add \\nthem to determine the weighted sum. Mathemati cally, we can calculate the weighted sum as \\nfollows:  \\n∑wi*xi = x1*w1 + x2*w2 +…wn*xn  \\nAdd a special term called  bias \\'b\\'  to this weighted sum to improve the model\\'s performance.  \\n∑wi*xi + b  \\nStep -2 \\nIn the second step, an activation function is applied with th e above -mentioned weighted sum, \\nwhich gives us output either in binary form or a continuous value as follows:  \\nY = f(∑wi*xi + b)  \\nCharacteristics of Perceptron  \\nThe perceptron model has the following characteristics.  \\n1. Perceptron is a machine learning algorithm  for supervised learning of binary classifiers.  \\n2. In Perceptron, the weight coefficient is automatically learned.  \\n3. Initially, weights are multiplied with input features, and the decision is made whether \\nthe neuron is fired or not.  \\n4. The activation function applies a step rule to check whether the weight function is \\ngreater than zero.  \\n5. The linear decision boundary is drawn, enabling the distinction between the two \\nlinearly separable classes +1 and -1. \\n6. If the added sum of all input values is more than the thres hold value, it must have an \\noutput signal; otherwise, no output will be shown.  \\nTypes of Perceptron Models  \\nBased on the layers, Perceptron models are divided into two types. These are as follows:  \\n1. Single -layer Perceptron Model  \\n2. Multi -layer Perceptron model  Single Layer Perceptron Model:  \\nThis is one of the easiest Artificial neural networks (ANN) types. A single -layered perceptron \\nmodel consists feed -forward network and also includes a threshold transfer function inside \\nthe model. The main objective of the sing le-layer perceptron model is to analyze the linearly \\nseparable objects with binary outcomes.  \\nIn a single layer perceptron model, its algorithms do not contain recorded data, so it begins \\nwith inconstantly allocated input for weight parameters. Further, it sums up all inputs \\n(weight). After adding all inputs, if the total sum of all inputs is more than a pre -determined \\nvalue, the model gets activated and shows the output value as +1.  \\nIf the outcome is same as pre -determined or threshold value, then the perfo rmance of this \\nmodel is stated as satisfied, and weight demand does not change. However, this model \\nconsists of a few discrepancies triggered when multiple weight inputs values are fed into the \\nmodel. Hence, to find desired output and minimize errors, some  changes should be necessary \\nfor the weights input.  \\n\"Single -layer perceptron can learn only linearly separable patterns.\"  \\nMulti -Layered Perceptron Model:  \\nLike a single -layer perceptron model, a multi -layer perceptron model also has the same model \\nstructure  but has a greater number of hidden layers.  \\nThe multi -layer perceptron model is also known as the Backpropagation algorithm, which \\nexecutes in two stages as follows:  \\no Forward Stage:  Activation functions start from the input layer in the forward stage and \\nterminate on the output layer.  \\no Backward Stage:  In the backward stage, weight and bias values are modified as per \\nthe model\\'s requirement. In this stage, the error between actual output and \\ndemanded originated backward on the output layer and ended on the i nput layer.  \\n \\nHence, a multi -layered perceptron model has considered as multiple artificial neural networks \\nhaving various layers in which activation function does not remain linear, similar to a single \\nlayer perceptron model. Instead of linear, activation function can be executed as sigmoid, \\nTanH, ReLU, etc., for deployment.  \\nA multi -layer perceptron model has greater processing power and can process linear and non -\\nlinear patterns. Further, it can also implement logic gates such as AND, OR, XOR, NAND, NOT, \\nXNOR, NOR.  \\n1. Structure : \\uf0b7 Single -Layer  Perceptron  (SLP) : It consists of only input and output \\nlayers. There are no hidden layers.  \\n\\uf0b7 Multilayer  Perceptron  (MLP) : It contains one or more hidden layers in \\naddition to the input and output layers.  \\n2. Functionality : \\n\\uf0b7 SLP: It can only learn linearly separable patterns. It uses a linear \\nactivation function, such as the step function or the sign function.  \\n\\uf0b7 MLP : It can learn non -linear patterns. It uses non -linear activation \\nfunctions in the hidden layers, such as the sigmoid, t anh, or ReLU \\nfunctions, allowing it to model complex relationships between inputs \\nand outputs.  \\n3. Learning  Algorithm : \\n\\uf0b7 SLP: It typically uses the perceptron learning rule or variants of gradient \\ndescent algorithms, such as the delta rule, to update the weights  and \\nbiases based on the error between predicted and actual outputs.  \\n\\uf0b7 MLP : It often uses backpropagation, a more generalized form of \\ngradient descent, to train the network. Backpropagation computes the \\ngradients of the loss function with respect to the weig hts and biases of \\nthe network, allowing for more efficient learning in multi -layer \\narchitectures.  \\n4. Applications : \\n\\uf0b7 SLP: It is suitable for simple classification tasks where the data is \\nlinearly separable.  \\n\\uf0b7 MLP : It is suitable for a wide range of tasks, includi ng classification, \\nregression, pattern recognition, and function approximation, especially \\nwhen dealing with non -linear relationships in the data.  \\n5. Flexibility : \\n\\uf0b7 SLP: It is limited in its ability to learn complex patterns due to its lack of \\nhidden layers and  linear activation functions.  \\n\\uf0b7 MLP : It is highly flexible and can learn complex relationships in data, \\nthanks to its ability to incorporate multiple hidden layers and non -\\nlinear activation functions.  \\n \\nMultilayer Networks and the Back propagation Algorithm  \\nExplain  about  Multilayer Neural Networks and draw the  \\narchitecture  of NN.  \\n  \\nA multilayer neural network, also known as a feedforward neural network or a deep \\nneural network, is a type of artificial neural network with multiple layers of artificial \\nneurons , including at least one hidden layer between the input and output layers. \\nThese networks are capable of learning and representing complex patterns and \\nrelationships in data, making them suitable for a wide range of machine learning \\ntasks, including image recognition, natural language processing, and more.  \\nHere\\'s a basic overview of a multilayer neural network:  \\n1. Input Layer: The input layer consists of input neurons, each representing a feature or \\nattribute of the input data. These neurons pass the input dat a to the hidden layers \\nfor processing.  \\n2. Hidden Layers: Multilayer neural networks have one or more hidden layers \\npositioned between the input and output layers. Each hidden layer contains multiple \\nartificial neurons (also called nodes or units). These neuro ns perform weighted sum \\nand activation functions, processing the information from the previous layer. The \\nactivation functions in hidden layers are typically nonlinear, such as the sigmoid \\n(logistic) function, ReLU (Rectified Linear Unit), or others.  \\n3. Weigh ts and Biases: Each connection between neurons (synapse) in the network has \\nan associated weight, and each neuron has a bias term. These weights and biases are \\nlearnable parameters that the network adjusts during training to minimize the error \\nbetween the predicted output and the actual target values.  \\n4. Weighted Sum and Activation: Within each hidden layer, each neuron computes a \\nweighted sum of the inputs from the previous layer, similar to the single -layer neural \\nnetwork. Then, this weighted sum is passed t hrough the chosen activation function \\nto introduce nonlinearity. This process is repeated for each neuron in the hidden \\nlayers.  \\n5. Output Layer: The output layer produces the final predictions or results of the \\nnetwork. The number of neurons in the output lay er depends on the specific task. \\nFor example, in a binary classification task, there may be two output neurons \\nrepresenting two classes. In a regression task, there could be a single output neuron \\nfor a continuous prediction.  \\n6. Activation Functions: Activati on functions in the hidden layers introduce nonlinearity \\ninto the network, allowing it to model complex relationships in the data. Common \\nactivation functions include the sigmoid, hyperbolic tangent (tanh), ReLU, and \\nvariants like Leaky ReLU or Parametric ReLU (PReLU).  \\n \\nBack propagation Algorithm : \\nBackpropagation, or backward propagation of errors, is an  algorithm  that is \\ndesigned to test for errors working back from output nodes to input nodes. It\\'s an \\nimportant mathematical tool for improving the accuracy of predictions in  data \\nmining  and machine learning . Essentially, backpropagation is an algorithm used to \\nquickly calculate derivatives in a  neural network , which are  the changes in output \\nbecause of tuning and adjustments.  \\nThere are two leading types of backpropagation networks:  \\n\\uf0b7 Static backpropagation.  Static backpropagation is a network developed \\nto map static inputs for static outputs. Static networks can solve stati c \\nclassification problems, such as optical character recognition ( OCR ). \\n\\uf0b7 Recurrent backpropagation.  The recurrent backpropagation network is \\nused for fixed -point learning. This means that during neural network \\ntraining, the weights are numerical values that determine how much \\nnodes -- also referred to as neurons -- influence output values. They\\'re \\nadjusted so that the network can achieve stability  by reaching a fixed \\nvalue.  \\nThe key difference here is that static backpropagation offers instant mapping, \\nwhile recurrent backpropagation does not.  \\nBackpropagation is a fundamental algorithm in training neural networks, enabling them to \\nlearn from data. H ere\\'s a concise overview of how it works:  \\n1. Forward  Pass : In the forward pass, input data is fed through the neural network, \\nlayer by layer, from the input layer to the output layer. Each layer applies a series  of \\ntransformations to the input data using its weights and activation functions, ultimate ly \\nproducing an output.  \\n2. Compute  Loss : Once the output is generated, it is compared to the actual target \\nvalues, and a loss function is calculated. The loss function measures the discrepancy  \\nbetween the predicted ou tput and the actual target.  \\n3. Backward  Pass (Backpropagation) : The goal of backpropagation is to adjust the \\nweights of the neural network in order to minimize the loss function. It works by \\npropagating the error backward from the output layer to the input la yer. a. Compute  Gradients : Starting from the output layer, the algorithm calculates the \\ngradient of the loss function with respect to the weights of each neuron. This is don e \\nusing the chain rule of calculus.  \\nb. Update  Weights : Once the gradients are computed, the weights of the network are \\nupdated in the opposite direction of the gradient in order to minimize the loss \\nfunction. This update can be done using optimization algorithms like Gradient \\nDescent, Adam, or RMSProp.  \\n4. Repea t: Steps 1 -3 are repeated iteratively for a certain number of epochs or until th e \\nmodel converges to a satisfactory solution.  \\nBy iteratively adjusting the weights based on the error calculated during the forward pass,  \\nbackpropagation allows neural networks  to learn from the data and improve their \\nperformance over time.  \\nWhy XOR problem could not be solved by simple \\nperceptron? And describe how a multilayer perceptron \\nsolve XOR problem.   \\nThe XOR problem couldn\\'t be solved by a simple perceptron because it\\'s not linearly \\nseparable. A perceptron is a single -layer neural network that uses a linear activation func tion. \\nLinear functions can only separate data points using a single straight line (or hyperplane in \\nhigher dimensions). However, the XOR pr oblem requires a non -linear decision boundary to \\ncorrectly classify the data.  \\nThe XOR problem involves inputs that are not linearly separable. In other words, no single \\nstraight line can separate the inputs of different classes (0 and 1) in a binary XOR fu nction. \\nHere\\'s the truth table for XOR:  \\nInput 1  Input 2  Output  \\n0 0 0 \\n0 1 1 \\n1 0 1 \\n1 1 0 \\nTo solve the XOR problem, a multilayer perceptron (MLP) is used. An MLP consists of one \\nor more hidden layers in addition to the input and output layers. Each neuron in the hidden  \\nlayer(s) uses a non -linear activation function, such as the sigmoid or ReLU function.  \\nHere\\'s how a multilayer perceptron (MLP) solves the XOR problem:  \\n1. Input  Layer : The input layer receives the XOR inputs (0 or 1).  \\n2. Hidden  Layer : The hidden layer(s) apply non -linear transformations to the input data \\nusing weighted connections and ac tivation functions. These non -linear \\ntransformations allow the MLP to learn and represent complex patterns in the data.  \\n3. Output  Layer : The output layer takes the outputs of the hidden layer(s) and produces \\nthe final output, which is the predicted XOR output  (0 or 1).  By using multiple layers with non -linear activation functions, the MLP can learn to create \\ncomplex decision boundaries that can solve the XOR problem. In essence, the hidden layers \\nallow the MLP to learn and represent the non -linear relationship s present in the XOR \\nfunction, enabling it to correctly classify the inputs.  \\n \\nhttps://www.techtarget.com/searchenterpriseai/definition/backpropagation -\\nalgorithm  \\nRemarks on Back Propagation Algorithm  \\nBackpropagation, short for \"backward propagation of errors,\" is a fundamental algorithm in the field \\nof artificial neural networks, particularly in training deep learning models. Here are some key \\nremarks on the backpropagation algorithm:  \\n \\nFoundation of Deep Learning: Backpropagation is the cornerstone algorithm behind the training of \\ndeep neural networks. It enables the optimization o f network parameters by efficiently computing \\nthe gradient of the loss function with respect to the model\\'s weights.  \\n \\nGradient Descent Optimization: Backpropagation is often used in conjunction with gradient descent \\nor its variants to iteratively update th e network weights in a way that minimizes the loss function. \\nThe gradient indicates the direction of steepest ascent, so by moving in the opposite direction, the \\nparameters are adjusted to minimize the loss.  \\n \\nChain Rule of Calculus: The backpropagation alg orithm leverages the chain rule of calculus to \\ncompute gradients efficiently. It breaks down the gradient calculation process layer by layer, \\npropagating errors backward from the output layer to the input layer.  \\n \\nForward and Backward Passes: Backpropagatio n involves two main steps: the forward pass and the \\nbackward pass. During the forward pass, input data is propagated through the network, and \\nactivations are computed layer by layer until the output is obtained. In the backward pass, gradients \\nof the loss function with respect to each parameter are computed recursively using the chain rule.  \\n \\nEfficient Computation: Backpropagation exploits computational efficiency by reusing intermediate \\nvalues computed during the forward pass to compute gradients during the  backward pass. This \\nreduces redundant computations and makes training feasible even for deep networks.  \\n \\nVanishing and Exploding Gradients: Backpropagation is susceptible to the vanishing and exploding \\ngradient problems, especially in deep networks. This o ccurs when gradients become extremely small \\nor large as they propagate backward through many layers. Techniques like gradient clipping and \\ncareful initialization of network weights help alleviate these issues.  \\n \\nActivation Functions: The choice of activatio n functions impacts the effectiveness of \\nbackpropagation. Common activation functions like ReLU (Rectified Linear Unit), sigmoid, and tanh \\nare used in different layers of the network, and they affect the gradient flow during backpropagation.  \\n \\nStochastic an d Mini -batch Gradient Descent: Backpropagation can be combined with different \\nvariants of gradient descent, including stochastic gradient descent (SGD) and mini -batch gradient descent, to update the network weights using subsets of the training data. This helps in achieving \\nfaster convergence and better generalization.  \\n \\nRegularization: Backpropagation can be augmented with regularization techniques such as L1 and L2 \\nregularization, dropout, and batch normalization to prevent overfitting and improve the \\ngene ralization performance of the model.  \\n \\nParallelization: Backpropagation is inherently parallelizable, allowing for efficient \\nimplementation on parallel computing architectures such as GPUs and TPUs. This \\nparallelization accelerates the training process, esp ecially for large -scale datasets and \\ncomplex models.  \\n \\nOverall, backpropagation is a powerful and versatile algorithm that forms the basis of training \\ndeep neural networks, enabling them to learn complex patterns from data and perform \\nvarious tasks in areas  such as image recognition, natural language processing, and \\nreinforcement learning . \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n UNIT-5 \\nEnsemble  Methods  \\n Introduction:  \\nWhat is Ensemble Methods?  \\nEnsemble methods are techniques that aim at improving the accuracy of results in models \\nby combining multiple models instead of using a single model. The combined models \\nincrease the accuracy of the results significantly. This has boosted the popularity of \\nensemble methods in  machine learning . \\n \\n \\nThe underlying concept behind ensemble learning is to combine the outputs of diverse \\nmodels to create a more precise prediction. By considering multiple perspectives and \\nutilizing the strengths of different models, ensemble learni ng+ improves the overall \\nperformance of the learning system. This approach not only enhances accuracy but also \\nprovides resilience against uncertainties in the data. By effectively merging predictions \\nfrom multiple models, ensemble learning has proven to b e a powerful tool in various \\ndomains, offering more robust and reliable forecasts.  \\nExample:  \\n \\nSuppose we have a dataset with the following features: Age, Income, and Education \\nLevel. Our target variable is whether a person buys a product (0 for not buying, 1 for \\nbuying).  \\nHere\\'s a simplified dataset:  \\nAge Income  Education Level  Buys Product  \\n35 50000  College  1 \\n45 80000  High School  0 \\n30 60000  High School  1 \\n40 70000  College  1 \\nNow, let\\'s apply bagging with decision trees:  \\n1. Bootstrap  Sampling:  We create multiple bootstrap samples from the original \\ndataset. Let\\'s create 5 bootstrap samples, each with 800 data points (80% of \\nthe original dataset size), allowing for replacement.  \\n2. Base  Model  Training:  For each bootstrap sample, we train a decision t ree \\nclassifier. Let\\'s say we decide to use decision trees with a maximum depth of 3.  \\n3. Aggregation:  To make predictions, we aggregate the predictions of all the \\nindividual decision trees. Since this is a classification task, we use majority \\nvoting. If more t han half of the decision trees predict class 1, the final \\nprediction is class 1; otherwise, it\\'s class 0.  \\n4. Prediction:  When a new data point comes in, each decision tree in the \\nensemble makes a prediction. Then, we use majority voting to get the final \\npredi ction of the ensemble.  \\n5. Evaluation:  We evaluate the performance of the ensemble model using \\nmetrics like accuracy, precision, recall, F1 -score, etc., on a separate validation \\ndataset.  \\n \\n \\nWhy Ensembling Methods:  \\n1. Reducing  Overfitting:  Ensemble methods help reduce overfitting, which \\noccurs when a model learns to perform well on the training data but fails to \\ngeneralize to unseen data. By combining multiple models trained on different \\nsubsets of data or using different algorithms, ensemb le methods can create a \\nmore generalized model that performs well on unseen data.  \\n2. Improving  Stability  and Robustness:  Ensemble methods are less sensitive to \\nnoise and outliers in the data compared to individual models. By averaging \\npredictions or using a v oting mechanism among multiple models, ensemble \\nmethods can produce more stable and robust predictions.  \\n3. Capturing  Complex  Relationships:  Different models may capture different \\naspects of the data or learn different patterns. Ensemble methods combine \\nthese diverse models to capture a broader range of relationships within the \\ndata, potentially leading to better overall performance.  4. Handling  Bias-Variance  Tradeoff:  Ensemble methods can effectively balance \\nthe bias -variance tradeoff. Individual models may suffe r from high bias \\n(underfitting) or high variance (overfitting). By combining multiple models, \\nensemble methods can achieve a better balance between bias and variance, \\nleading to improved performance.  \\n5. Enhancing  Predictive  Accuracy:  Ensemble methods often ou tperform \\nindividual models in terms of predictive accuracy. By leveraging the wisdom of \\nthe crowd, ensemble methods can achieve higher accuracy by aggregating the \\npredictions of multiple models.  \\n6. Flexibility  and Versatility:  Ensemble methods are versatile a nd can be \\napplied to various machine learning algorithms, including decision trees, \\nneural networks, support vector machines, and more. They can also be \\nadapted to different types of learning tasks, such as classification, regression, \\nand clustering.  \\n \\nAppl ications of Ensemble Methods:  \\nEnsemble learning is a fairly common strategy in deep   learning and has been applied to tackle a \\nmyriad of problems. It has helped tackle complex pattern recognition tasks that require computers \\nto learn high -level  semantic information  from digital images or videos, like object detection, \\nwhere  bounding boxes need to be formed  around the ob jects of interest and image classification.  \\n1)Disease detection  \\nClassification and localization of diseases for simplistic and fast prognosis have been aided by \\nEnsemble learning, like in cardiovascular disease detection from X -Ray and CT scans.  \\n2)Remote Sensing  \\nMonitoring of physical characteristics of a target area without coming in physical contact, called \\nRemote Sensing, is a difficult task since the data acquired by different sensors have varying \\nresolutions leading to incoherence in data distribution . \\nTasks like Landslide Detection and Scene Classification have also been accomplished with the help \\nof Ensemble Learning.  3) Fraud Detection  \\nDetection of digital fraud is an important and challenging task since very minute precision is \\nrequired to automate  the process. Ensemble Learning has proved its efficacy in detecting  Credit \\nCard Fraud  and Impression Fraud.  \\n4)Speech emotion recognition  \\nEnsemble Learning is also applied in speech emotion recognition, especially in the case of multi -\\nlingual environments. The technique allows for the combining of all classifiers’ effect instead of \\nchoosing one classifier and compromising certain language corpus’s accuracy.  \\nRobotics and Autonomous Vehicles:  \\n \\nIn robotics and autonomous vehicles, ensembles may involve combining pr edictions from \\nvarious sensors and perception models. This helps improve decision -making in dynamic \\nenvironments and enhances the system\\'s adaptability to diverse scenarios.  \\n5)Natural Language Processing (NLP):  \\n \\nIn sentiment analysis, ensemble methods can blend predictions from models utilizing \\ndifferent features, such as bag -of-words, word embeddings, or attention mechanisms. This \\nhelps capture a broader range of linguistic patterns and nuances in sentiment expression.  \\n6)Classification and Regression:  \\n \\nRandom Forests: A Random Forest is an ensemble of decision trees, where each tree is \\ntrained on a random subset of the data and makes independent predictions. The final \\nprediction is often an average or a majority vote of individual tree predictions.  \\nGradient  Boosting Machines (GBM): GBM builds trees sequentially, with each tree focusing \\non correcting the errors of the previous ones. It combines weak learners into a strong one, \\noften achieving high accuracy and generalization on complex tasks.  \\nAdaBoost: AdaBoo st assigns higher weights to misclassified instances, forcing subsequent \\nmodels to focus on the harder -to-classify examples. It combines the weighted predictions to \\nform a robust final model.  \\nWhat  is Boosting  in Ensemble  Learning?   \\nBoosting is an ensemble learning method that involves training homogenous weak \\nlearners  sequentially  such that a base model depends on the previously fitted base models. \\nAll these base learners are then combined in a very adaptive way to obtain an ensemble \\nmodel.   \\nIn boosting, th e ensemble model is the  weighted  sum  of all constituent base learners. There \\nare two meta -algorithms in boosting that differentiate how the base models are aggregated:  \\n1. Adaptive Boosting (AdaBoost)  \\n2. Gradient Boosting  \\nHow  Boosting  Works?  \\nBoosting consists of multiple weak learners that are fitted iteratively in a manner that each \\nnew learner gives more weight or is only trained with observations that have been poorly \\nclassified by the previous learners.  \\nAt the end of this process, we obtain a strong learner (e nsemble model) with  lesser  \\nbias than the individual base models composing it. Hence, boosting techniques help  avoid  \\nthe underfitting  of the model. So, when a base model usually has low variance but high bias, \\nwe will implement boosting techniques. Another reason is that such models are generally \\nless computationally expensive to fit.  \\n \\n \\nHow  is a boosting  model  trained  to make  predictions?  \\n \\n \\n \\n \\n1. Samples generated from the training set are assigned the  same  weight  to start \\nwith. These samples are used to train a homogeneous weak learner or base \\nmodel.  \\n2. The prediction error for a sample is calculated – the greater  the error,  the weight  \\nof the sample  increases . Hence, the sample becomes more important for \\ntraining the next base model.  \\n3. The individual learner is weighted too – does  well on its predictions,  gets  a \\nhigher  weight  assigned  to it. So, a model that outputs good predictions will have \\na higher say in the final decision.  \\n4. The weighted data is then passed on to the following base model,  and steps 2) \\nand 3) a re repeated until the  data  is fitted  well enough  to reduce  the error  \\nbelow  a certain  threshold . \\n5. When new data is fed into the boosting model, it is passed through all individual \\nbase models, and  each  model  makes  its own  weighted  prediction . \\n6. Weight of these  models is used to generate the final prediction. The predictions \\nare scaled and  aggregated  to produce  a final  prediction . \\n \\nTypes of Boosting Algorithms  \\nAdaBoost (Adaptive Boosting)  \\n\\uf0b7 AdaBoost is the most popular boosting algorithms.  \\n\\uf0b7 It assigns weights to training instances and adjusts these weights based on the \\nperformance of weak learners.  \\n\\uf0b7 It focuses on misclassified instances, allowing subsequent weak learners to \\nconcentrate on these samples.  \\n\\uf0b7 The final prediction is determined by aggregating the predicti ons of all weak \\nlearners through a weighted majority vote.  \\nAdaBoost, short for Adaptive Boosting, is an ensemble machine \\nlearning algorithm that can be used in a wide variety of classification \\nand regression tasks. It is a supervised learning algorithm tha t is used \\nto classify data by combining multiple weak or base learners (e.g., \\ndecision trees) into a strong learner. AdaBoost works by weighting the \\ninstances in the training dataset based on the accuracy of previous \\nclassifications.   \\nAdaBoost in machine learning is one of these predictive modelling \\ntechniques. AdaBoost, also known as Adaptive Boosting, is a Machine \\nLearning approach that is utilised as an Ensemble Method. AdaBoost\\'s \\nmost commonly used estimator is decision trees with one level, which \\nis decision trees with just one split. These trees are often referred to \\nas Decision Stumps.  \\nThis approach constructs a model and assigns equal weights to all \\ndata points. It then applies larger weights to incorrectly categorised \\npoints. In the following model , all points with greater weights are given \\nmore weight. It will continue to train models until a smaller error is \\nreturned.  \\n \\nAdaBoost in Machine Learning  \\nTo illustrate, imagine you created a  decision tree algorithm  using the \\nTitanic dataset and obtained an accuracy of 80%. Following that, you \\nuse a new method and assess the accuracy, which is 75% for KNN \\nand 70% for Linear Regression.  \\nWhen we develop a new model on the same dataset, the accuracy \\nvaries. What if we combine all of these algorithms to create  the final \\nprediction? Using the average of the outcomes from various models \\nwill yield more accurate results. In this method, we can improve \\nprediction power.  \\n1. Initialization : Each data point in the training set is assigned an equal weight.  \\n2. Iterative  Learning : AdaBoost iteratively trains a sequence of weak learners. A \\nweak learner is a simple model that performs slightly better than random \\nchance, for example, a decision stump (a decision tree with a single split).  \\n3. Weighted  Training : In each iteration,  the algorithm adjusts the weights of \\nincorrectly classified data points, giving higher weights to the misclassified \\npoints. This means that the next weak learner will focus more on the points \\nthat were misclassified by the previous weak learners.  \\n4. Combinat ion of Weak  Learners : After all the weak learners are trained, \\nAdaBoost combines them into a strong learner by assigning a weight to each \\nweak learner based on its accuracy.  \\n5. Final  Model : To make predictions, AdaBoost combines the predictions of all \\nthe wea k learners, weighted by their individual accuracies.  \\n \\nGradient Boosting  \\n\\uf0b7 Gradient Boosting is a widely used boosting algorithm that builds an ensemble of \\ndecision trees.  \\n\\uf0b7 It works by minimizing a loss function, such as mean squared error or log loss, \\nthrough  gradient descent.  \\n\\uf0b7 In each iteration, the algorithm adds a new decision tree to correct the errors \\nmade by the previous trees.  \\n\\uf0b7 By iteratively updating the model, gradient boosting gradually improves the \\npredictive accuracy.  XGBoost (Extreme Gradient Boosti ng) \\n\\uf0b7 XGBoost is an advanced boosting algorithm that combines gradient boosting with \\nregularization techniques.  \\n\\uf0b7 It incorporates both tree -based models and linear models to enhance \\nperformance and efficiency.  \\n\\uf0b7 It uses a combination of gradient boosting and regularization strategies to prevent \\noverfitting.  \\n\\uf0b7 It is known for its speed, scalability, and ability to handle large -scale datasets \\neffectively.  \\nLightGBM (Light Gradient Boosting Machine)  \\n\\uf0b7 LightGBM is a high -performance boosting algorithm that uses a leaf -wise \\napproach to construct decision trees.  \\n\\uf0b7 It prioritizes growing the leaf nodes that reduce the loss the most, resulting in \\nfaster training times.  \\n\\uf0b7 It is particularly efficient when dealing with large datasets and is widely used in \\ncompetitions and industr y applications.  \\nCatBoost  \\n\\uf0b7 CatBoost is a boosting algorithm designed specifically for categorical data.  \\n\\uf0b7 It handles categorical features directly, eliminating the need for pre -processing, such a s \\none-hot encoding.  \\n\\uf0b7 It incorporates gradient boosting and symmetric trees to achieve high prediction accuracy \\nwhile efficiently handling categorical variables.  \\nStochastic Gradient Boosting  \\n\\uf0b7 Stochastic Gradient Boosting is an extension of gradient boosting that introduces \\nrandomness during tree construction.  \\uf0b7 It randomly selects a subset of features and samples, providing diversity in the weak \\nlearners.  \\n\\uf0b7 This randomness helps prevent overfitting and improves the generalization ability of the \\nmodel.  \\nWhat Is Bagging in Machine Learning?  \\nBagging, also known as Bootstr ap aggregating, is an ensemble learning technique that helps \\nto improve the performance and accuracy of machine learning algorithms. It is used to deal \\nwith bias -variance trade -offs and reduces the variance of a prediction model. Bagging avoids \\noverfitting  of data and is used for both regression and classification models, specifically for \\ndecision tree algorithms.  \\n \\nWhat Is Bootstrapping?  \\nBootstrapping is the method of randomly creating samples of data out of a population with \\nreplacement to estimate a population parameter . \\n \\nSteps in Bagging:  \\n1. Bootstrap  Sampling:  We create multiple bootstrap samples from the original \\ndataset. Let\\'s create 5 bootstrap samples, each with 800 data points (80% of \\nthe original dataset size), allowing for replacement.  \\n2. Base  Model  Training:  For each bootstrap sample, we train a decision tree \\nclassifier. Let\\'s say we decide to use decision trees with a maximum depth of 3.  \\n3. Aggregation:  To make predictions, we aggregate the predictions of all the \\nindividual decision trees. Since this is a classification task, we use majority \\nvoting. If more than half of the decision trees predict class 1, the final \\nprediction is class 1; otherwise, it\\'s class 0.  \\n4. Prediction:  When a new data point comes in, each decision tree in the \\nensemble makes a  prediction. Then, we use majority voting to get the final \\nprediction of the ensemble.  \\n   5.  Evaluation:  We evaluate the performance of the ensemble model using metrics like  \\naccuracy, precision, recall, F1 -score, etc., on a separate validation dataset  \\n \\nSuppose we have the following predictions from each decision tree in the ensemble for a \\nnew data point:  \\n\\uf0b7 Tree 1 predicts: 1 (buy)  \\n\\uf0b7 Tree 2 predicts: 0 (not buy)  \\n\\uf0b7 Tree 3 predicts: 1 (buy)  \\nTo aggregate these predictions using majority voting:  \\n\\uf0b7 Predicted class 0 (not buy): 1 vote  \\n\\uf0b7 Predicted class 1 (buy): 2 votes  \\nSince the majority of trees (2 out of 3) predict class 1 (buy), we would classify the data point \\nas \"buy\" based on the majority vote.  \\nIn this simple example, we can see that by aggregating the predictions of multiple decision \\ntrees, we can make a more robust prediction compared to relying on just one decision tree.  \\nApplication of the Bagging:  \\nThere are various applications of Bagging, which are given below - \\n1. IT:  Bagging can also improve the precision and accuracy of IT structures, together \\nwith network intrusion detection structures. In the meantime, this study seems at how \\nBagging can enhance the accuracy of network intrusion detection and reduce the rates \\nof fake positives.  \\n2. Environment:  Ensemble techniques, together with Bagging, were carried out inside \\nthe area of far -flung sensing. This study indicates how it has been used to map the \\nstyles of wetlands inside a coastal landscape.  \\n3. Finance:  Bagging has als o been leveraged with deep gaining knowledge of models \\nwithin the finance enterprise, automating essential tasks, along with fraud detection, \\ncredit risk reviews, and option pricing issues. This research demonstrates how Bagging \\namongst different device st udying techniques was leveraged to assess mortgage \\ndefault hazard. This highlights how Bagging limits threats by saving you from credit \\nscore card fraud within the banking and economic institutions.  \\n4. Healthcare:  The Bagging has been used to shape scienti fic data predictions. These \\nstudies (PDF, 2.8 MB) show that ensemble techniques had been used for various \\nbioinformatics issues, including gene and protein selection, to perceive a selected trait \\nof interest. More significantly, this study mainly delves in to its use to expect the onset \\nof diabetes based on various threat predictors.  \\nAdvantages of Bagging in Machine Learning  \\n\\uf0b7 Bagging minimizes the overfitting of data  \\n\\uf0b7 It improves the model ’s accuracy  \\n\\uf0b7 It deals with higher dimensional data efficiently  \\n\\uf0b7  \\nSimilarities  Between  Bagging  and Boosting  \\n \\nBagging and Boosting, both being the commonly used methods, have a universal similarity \\nof being classified as ensemble methods. Here we will explain the similarities between \\nthem.  \\n1. Both are ensemble methods to get  N learners from 1 learner.  \\n2. Both generate several training data sets by random sampling.  \\n3. Both make the final decision by averaging the N learners (or taking the majority \\nof them i.e Majority Voting).  \\n4. Both are good at reducing variance and provide higher st ability.  \\n \\nDifferences  Between  Bagging  and Boosting  \\n S.NO  Bagging  Boosting  \\n1. The simplest way of combining predictions that   \\nbelong to the same type.  A way of combining predictions \\nthat  \\nbelong to the different types.  \\n2. Aim to decrease variance, not bias.  Aim to decrease bias, not \\nvariance.  \\n3. Each model receives equal weight.  Models are weighted according to \\ntheir performance.  \\n4. Each model is built independently.  New models are influenced   \\nby the performance of previously \\nbuilt models.  \\n5. Different training data subsets are selected using \\nrow sampling with replacement and random \\nsampling methods from the entire training dataset.  Every new subset contains the \\nelements that were misclassified \\nby previous models.  \\n6. Bagging tries to solve the  over -fitting problem.  Boosting tries to reduce bias.  \\n7. If the classifier is unstable (high variance), then apply \\nbagging.  If the classifier is stable and \\nsimple (high bias) the apply \\nboosting.  \\n8.  In this base classifiers are trained parallelly.  In thi s base classifiers are trained \\nsequentially.  \\n9 Example: The Random forest model uses Bagging.  Example: The AdaBoost uses \\nBoosting techniques  \\n \\nCombinational Methods:  \\n \\nEnsemble learning in machine learning involves combining the predictions of multiple \\nmodels to improve overall performance and robustness. Combinational methods refer to \\nthe techniques used to combine these individual models within an ensemble. There are \\ntwo main types of ensemble methods: averaging methods and boosting methods.  \\n Averaging  Methods:  \\n \\nSimple Averaging : In this method, the predictions of individual models are averaged to \\nobtain the final prediction. This is commonly used for regression problems.  \\nWeighted Averaging:  Each model\\'s prediction is multiplied by a weight, and the wei ghted \\npredictions are then averaged. The weights can be assigned based on the models\\' \\nperformance on a validation set or other criteria.  \\nBoosting Methods:  \\n \\nAdaptive Boosting (AdaBoost) : AdaBoost assigns weights to training instances and adjusts \\nthem based on the error of the previous models. It focuses more on instances that were \\nmisclassified by previous models, effectively giving them higher importance in subsequent \\nmodels.  \\nGradient Boosting:  This approach builds trees sequentially, with each tree trying to correct \\nthe errors of the previous one. The final prediction is the sum of the predictions of all the \\ntrees.  \\nXGBoost, LightGBM, and CatBoost : These are popular gradient boosting frameworks that \\noptimize and extend traditional gradient boosting algorithm s for improved speed and \\nperformance.  \\n \\nVoting Methods:  \\n \\nMajority Voting:  In classification problems, the class that receives the majority of votes \\nfrom individual models is selected as the final prediction.  \\nWeighted Voting:  Similar to weighted averaging, m odels are assigned weights, and the \\nclass with the highest weighted sum of votes is chosen.  \\n \\nStacking (Meta -Ensemble):  \\n \\nMeta -Learner:  A separate model, often referred to as a meta -learner or blender, is trained \\nto make predictions based on the outputs of i ndividual models. The predictions of the \\nbase models become the input features for the meta -learner.  \\nStacked Generalization:  Stacking involves training multiple models and combining them \\nwith a meta -learner. It aims to capture the strengths of individual m odels while mitigating \\ntheir weaknesses.  \\n \\nBagging (Bootstrap Aggregating):  \\n \\nRandom Forest:  Random Forest is a popular bagging ensemble method that builds \\nmultiple decision trees and combines their predictions. Each tree is trained on a random \\nsubset of the training data.  \\nBootstrap Aggregating:  In bagging, multiple models are trained independent ly on different \\nsubsets of the training data, and their predictions are averaged or voted upon.  \\nEnsemble methods are powerful tools for improving the performance and generalization \\nof machine learning models, and the choice of combinational method depends on the \\nspecific characteristics of the dataset and the underlying models used in the ensemble.   \\n \\nBenefits of Combination   \\nsome key advantages of these combinational methods  \\nAveraging Methods:  \\n \\nReduction of Overfitting:  \\n \\nAveraging helps to reduce overfitting by combining the predictions of multiple models, which may \\nhave different sources of error. This can lead to a more generalized and robust model.  \\nStability:  \\n \\nAveraging tends to produce more stable and reliable predictions, particularly when ind ividual models \\nin the ensemble have high variance. By smoothing out individual model fluctuations, the ensemble \\nbecomes less sensitive to noise in the training data.  \\n \\nImproved Accuracy:  \\n \\nAveraging can lead to improved accuracy, especially when individual m odels have complementary \\nstrengths and weaknesses. The ensemble\\'s performance often surpasses that of its individual \\ncomponents.  \\n \\nBetter Handling of Outliers:  \\n \\nOutliers or anomalies in the training data may disproportionately affect individual models. Averaging \\nhelps mitigate the impact of outliers by considering the collective wisdom of the ensemble.  \\n \\nEnhanced Robustness:  \\n \\nAveraging provides a form of regularization by combining models with different characteristics. This \\nenhances the ensemble\\'s abilit y to generalize well to new, unseen data.  \\n \\nVoting Methods:  \\n \\nDiversity and Error Correction:  \\n \\nVoting methods leverage the diversity among individual models in the ensemble. If models make \\ndifferent errors on different instances, the ensemble can correct the se errors through a majority or \\nweighted voting scheme.  \\n \\nHandling Model Uncertainty:  \\n \\nVoting is effective when dealing with uncertainty in model predictions. By considering the collective \\ndecision of multiple models, the ensemble can provide more confident  predictions, especially in \\nsituations where individual models may be unsure.   \\nApplicability to Various Model Types:  \\n \\nVoting methods can be applied to a wide range of base models, including different machine learning \\nalgorithms. This flexibility allows for  the creation of diverse ensembles, which often leads to \\nimproved performance.  \\n \\nSimplicity and Interpretability:  \\n \\nVoting methods are often straightforward and easy to understand. The final decision is based on a \\ndemocratic process, making it interpretable and transparent, which can be important in certain \\napplications.  \\nScalability:  \\nVoting methods can be easily scaled by adding more models to the ensemble. As long as the \\nindividual models contribute some useful information, the ensemble is likely to benefit from \\nthe increased diversity.  \\nExplain  Random  Forest  Algorithm  and give example.  \\nRandom Forest is a popular machine learning algorithm that belongs to the supervised \\nlearning technique. It can be used for both Classification and Regression problems in \\nML. It is based on the concept of  ensemble learning,  which is a process of  combining \\nmultiple classifiers to solve a complex problem and to improve the performance of the \\nmodel.  \\n\\uf0b7 As the name suggests,  \"Random Forest is a classifier that contains a number \\nof dec ision trees on various subsets of the given dataset and takes the \\naverage to improve the predictive accuracy of that dataset.\"  Instead of \\nrelying on one decision tree, the random forest takes the prediction from each \\ntree and based on the majority votes of  predictions, and it predicts the final \\noutput.  \\n\\uf0b7 The greater number of trees in the forest leads to higher accuracy and \\nprevents the problem of overfitting.   \\nRandom Forest works in two -phase first is to create the random forest by combining \\nN decision tree, and second is to make predictions for each tree created in the first \\nphase.  \\nThe Working process can be explained in the below steps and diagram:  \\nStep -1: Select random K data points from the training set.  \\nStep -2: Build the decision trees associated wi th the selected data points (Subsets).  \\nStep -3: Choose the number N for decision trees that you want to build.  \\nStep -4: Repeat Step 1 & 2.  \\nStep -5: For new data points, find the predictions of each decision tree, and assign the \\nnew data points to the category  that wins the majority votes.  \\nExample:  Suppose there is a dataset that contains multiple fruit images. So, this \\ndataset is given to the Random forest classifier. The dataset is divided into subsets and \\ngiven to each decision tree. During the training phas e, each decision tree produces a \\nprediction result, and when a new data point occurs, then based on the majority of \\nresults, the Random Forest classifier predicts the final decision. Consider the below \\nimage:  \\n \\n \\n \\n \\n \\n \\n \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "2aEMj4sHYhpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9C0poo9Z5O1",
        "outputId": "19d413ef-849d-45f3-b305-d1f75d045962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "355"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=\"AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "q-GbGtclZ8UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_search = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "id": "ATJBMzJhaRAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_search\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwMcQbGkaUfD",
        "outputId": "278e51a9-cb6e-4709-be11-a8d77c6af310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7c952812c850>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "EkE3YEXpaY3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain\n",
        "\n",
        "from langchain.llms import GooglePalm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLtudYFaadwA",
        "outputId": "8fd0b2e0-9576-417e-c8f1-fcddb031cb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    temperature = 0,\n",
        "    max_tokens = None,\n",
        "    timeout= None,\n",
        "    max_retries= 2,\n",
        "    google_api_key=\"AIzaSyBMSi3Bx9WqfQPHACdfdCCcGsSHBRvUieI\"\n",
        ")\n",
        ", chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "f7PtOnrWa289"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is machine learning?\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "TKkudXu4bt-R",
        "outputId": "ab7bca90-1640-4b4f-ef12-2674468a0d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Machine learning is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Association Learning?\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "xVqkNXaOcDR_",
        "outputId": "8ebc1733-0a18-459f-9180-dfb4706d2dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Association learning is a type of unsupervised learning used to identify patterns in data. It works by finding relationships between different items in a dataset. \\n\\nHere\\'s a breakdown:\\n\\n* **Goal:** To discover interesting relationships or associations between items in a dataset.\\n* **Method:**  It analyzes data to find frequent itemsets (groups of items that occur together often) and then generates rules that describe these relationships.\\n* **Example:** The classic \"beer and diapers\" story, where a retail store supposedly discovered that men often bought beer and diapers together. This illustrates how association learning can reveal unexpected relationships.\\n\\n**Key Concepts:**\\n\\n* **Rules:**  Association learning uses rules of the form X → Y, where X and Y are sets of items. This means \"If X is present, then Y is likely to be present.\"\\n* **Support:**  The proportion of transactions in the database that contain both X and Y. It measures how common the itemset is.\\n* **Confidence:**  The probability that a transaction containing X also contains Y. It measures the reliability of the rule.\\n\\n**Applications:**\\n\\nAssociation learning has many applications, including:\\n\\n* **Retail:** Market basket analysis to understand customer buying habits and optimize promotions and store layouts.\\n* **Healthcare:** Identifying combinations of symptoms and diagnoses that frequently occur together, aiding in diagnosis.\\n* **Web Usage Mining:** Analyzing patterns in web usage data to improve website design and personalize content delivery.\\n* **Finance:** Fraud detection by identifying unusual patterns of transactions. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"vikisit bharat\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "X6fHprqmclIH",
        "outputId": "d0cbe8ef-92bc-4f20-ce4e-fa3cb852c57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'m sorry, I don\\'t understand what \"vikisit bharat\" means. Could you please clarify or rephrase your question? \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Types of regression\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "40pbNENMcuXy",
        "outputId": "a1281064-2958-4c22-898c-9dec2f127d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here are some common types of regression, based on the provided context:\\n\\n* **Linear Regression:**  Used when there's a linear relationship between variables.  For example, predicting sales based on advertising spending.\\n* **Logistic Regression:** Used when the target variable is binary (two classes, like yes/no or success/failure).  It predicts the probability of an event happening.  Examples include customer churn prediction or fraud detection.\\n* **Polynomial Regression:** Extends linear regression by using polynomial equations (quadratic, cubic, etc.) to model more complex relationships.  This can be useful when the relationship between variables isn't strictly linear.\\n* **Multinomial Logistic Regression:** Used when the target variable has more than two discrete outcomes (categories).  For example, predicting the most popular transportation type in the future. \\n\\nThe context also mentions that regression models can be simple and easy to understand, but they can also hide inaccuracies or oversimplifications. It's important to choose the right type of regression for your specific problem and to be aware of its limitations. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_c2fSOWeAoYG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}